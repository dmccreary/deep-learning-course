{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>Welcome to our website.</p>"},{"location":"checklist/","title":"Site Checklist","text":"<ol> <li>Customize the fields in your mkdocs.yml file</li> <li>Configure Google Analytics to use the right site ID</li> <li>Make sure that your .gitignore file includes the <code>site</code> directory</li> <li>Test the build</li> <li>Make sure the Edit button appears</li> <li>Make sure that code color heightening renders correctly</li> <li>run <code>git config advice.addIgnoredFile false</code></li> </ol>"},{"location":"contact/","title":"Contact","text":"<p>Please contact me on LinkedIn</p> <p>Thanks! - Dan</p>"},{"location":"course-description/","title":"Course Description","text":"<p>Organization: University of Minnesota Department of Electrical Engineering and Computer Design (EECD) Course Identifier: EE 4940 Course Title: : Introduction to Deep Learning Offering Date: Spring 2025</p>"},{"location":"course-description/#course-instructor","title":"Course Instructor","text":"<p>Sang-Hyun Oh, Professor of ECE, graduate faculty in neuroscience, physics, biomedical eng. Email: sang@umn.edu Office: 5-119 Keller Hall Teaching Assistant: Ike Goetzman (PhD candidate in ECE; email: goetz219@umn.edu) Lecture (Jan 22 \u2013 May 5, 2024): Monday/Wednesday 11:15am-12:30pm @ Appleby Hall 3</p>"},{"location":"course-description/#course-summary","title":"Course Summary","text":"<p>Machine learning, especially deep learning based on neural networks, has shown transformative impacts across life sciences, engineering, and medicine, as recently highlighted by the 2024 Nobel Prizes: </p> <ul> <li>The Physics Nobel was awarded to John Hopfield and Geoffrey Hinton for pioneering contributions to neural networks that enable machine learning</li> <li>Demis Hassabis, John Jumper, and David Baker received the Chemistry Nobel for advancing computational protein design.</li> </ul>"},{"location":"course-description/#course-overview","title":"Course Overview","text":"<p>EE 4940: Introduction to Deep Learning aims to provide students with both fundamental and applied perspectives on these advances. Beginning with an overview of AI, the course introduces deep neural networks (DNNs) through practical, hands-on examples and guides students through specialized neural network architectures, including</p> <ul> <li>convolutional neural networks (CNNs) for diagnostic applications and </li> <li>recurrent neural networks (RNNs) for time series analysis.</li> </ul> <p>Emphasis is placed on applying neural networks to tackle real-world problems in classification, regression, image analysis, and time-series prediction. Scientific applications are demonstrated as well, such as using DNNs to solve equations.</p> <p>The course concludes with dimensionality reduction techniques, followed by advanced topics such as generative AI, and an introduction to reinforcement learning. </p> <p>Emphasis will be on practical experience with Python-based coding over mathematical theory.</p> <p>By the end of the course, students will have gained familiarity with Python-driven deep learning, hands-on skills, and a working knowledge of deep learning\u2019s potential for a wide range of problems.</p>"},{"location":"course-description/#course-prerequisites","title":"Course Prerequisites","text":"<p>EE 4940 - Special Topics in Electrical and Computer Engineering is recommended but not required.</p> <p>This course is designed to be accessible and introductory, with essential concepts and coding skills introduced as needed.</p>"},{"location":"course-description/#expected-workload","title":"Expected Workload","text":"<p>This course (EE 4940) is a 3-credit, lecture format course. The expected workload for this course this semester is, on average, 45 hours per credit, or just over 3 hours per credit hour per week (including lecture). The total workload of 9 hours per week.</p>"},{"location":"course-description/#course-goals-and-objectives","title":"Course Goals and Objectives","text":"<p>EE 4940 aims to equip students with a foundation in deep learning, focusing on core architectures like deep neural networks (DNNs), convolutional neural networks (CNNs), and recurrent neural networks (RNNs).</p> <p>Through hands-on applications, students will learn to apply these models to solve practical problems using real-world datasets, such as cancer diagnostics and time-series analysis. The primary goal of the course is to develop students's ability to implement and troubleshoot neural network models, gaining some practical experiences, and be aware of potential pitfalls/artifacts while using DNNs.</p> <p>By the course's end, students will have a working knowledge of AI\u2019s role in scientific problem-solving, dimensionality reduction techniques, and a simple introduction to generative models and reinforcement learning (RL).</p>"},{"location":"course-description/#topics-to-be-covered","title":"Topics To Be Covered","text":""},{"location":"course-description/#1-introduction-to-ai-and-deep-learning","title":"1. Introduction to AI and deep learning","text":"<ul> <li>Brief history of AI, neural networks and recent Nobel-winning breakthroughs in physics and chemistry</li> <li>Course setup, tools, and brief introduction to Python for deep learning</li> <li>The universality theorem and the manifold hypothesis</li> </ul>"},{"location":"course-description/#2-fundamentals-of-deep-neural-networks-dnns","title":"2. Fundamentals of Deep Neural Networks (DNNs)","text":"<ul> <li>Architecture of DNNs: layers, activation functions, and backpropagation</li> <li>Training, validation, and testing sets;</li> <li>Loss functions, gradient descent, mini-batches</li> <li>Hands-on coding</li> </ul>"},{"location":"course-description/#3-convolutional-neural-networks-cnns-applications-in-diagnostic-imaging","title":"3. Convolutional Neural Networks (CNNs) - applications in diagnostic imaging","text":"<ul> <li>CNN architecture</li> <li>Applying CNNs, with MHIST as a case study for cancer diagnosis</li> </ul>"},{"location":"course-description/#4-recurrent-neural-networks-rnns-and-time-series-analysis","title":"4. Recurrent Neural Networks (RNNs) and time series analysis","text":"<ul> <li>Introduction to RNNs, LSTMs, for sequency data analysis.</li> <li>Hands-on practice with real-world data.</li> </ul>"},{"location":"course-description/#5-chips-and-ai","title":"5. Chips and AI","text":"<p>Briefly explore AI chips, neuromorphic devices, and future directions.</p>"},{"location":"course-description/#6-ai-for-scientific-problem-solving-using-neural-networks-to-approximate-solutions-for","title":"6. AI for scientific problem solving: Using neural networks to approximate solutions for","text":"<p>Maxwell\u2019s equations</p>"},{"location":"course-description/#7-dimensionality-reduction-and-autoencoders","title":"7. Dimensionality reduction and autoencoders","text":""},{"location":"course-description/#8-advanced-topics","title":"8. Advanced topics","text":""},{"location":"course-description/#course-format","title":"Course Format","text":"<ul> <li>Classroom lectures only</li> <li>Canvas LMS link will be provided</li> <li>Textbook and Required Materials: none</li> <li>Based on lecture notes (uploaded in canvas 1-2 days before class)</li> </ul>"},{"location":"course-description/#homework-assignments-and-mini-projects","title":"Homework Assignments and \u201cMini-projects\u201d:","text":"<ul> <li>Regularly-scheduled weekly or biweekly homework assignments and 4 multi-week \u201cmini-projects.\u201d The former will be designed to exercise basic concepts and modest extensions of the technical or computational tools introduced in class; the latter will be crafted to allow students to take a \u201cdeeper dive\u201d by applying techniques developed in the course to data sets arising in various aspects of ECE and life sciences.</li> <li>You are allowed (in fact, encouraged) to work with others when solving the homework and mini project problems. However, solutions submitted for grading should be formulated by each student independently! Late homework and mini-project submissions will be accepted, but without a legitimate (e.g., illness-based) justification, will result in a maximum grade of 80% for that assignment. Specifically, unjustified late assignments will be graded according to the same rubric as on-time assignments, but the corresponding score will be multiplied by 0.8 when entered into the gradebook.</li> </ul>"},{"location":"course-description/#exams","title":"Exams","text":"<p>There will be one midterm exam and one final exam. The midterm exam will be open book/notes. The final exam will be open book/notes and will be due no earlier than the final exam time specified by the Registrar. Either or both may be take-home exams.</p>"},{"location":"course-description/#grading","title":"Grading","text":"<p>The grade distributions for the course variations are provided below.</p> <p>Note: distributions for homework assignments and mini-projects are total; individual submissions will be equally weighted.</p> Deliverable Weight Homework Assignments 40% Mini-projects 40% Midterm Exam 10% Final Exam 10%"},{"location":"course-description/#software-requirements","title":"Software Requirements","text":"<p>Through the homework assignments and mini-projects, students will be required to perform a number of computer exercises to become familiar with the computational and practical aspects of deep learning. This will typically entail utilization of Python, often in concert with existing toolboxes such as NumPy, SciPy, Matplotlib, Scikit-learn, and PyTorch (or TensorFlow), all of which are freely available for Windows, Mac, and Linux operating systems.</p> <p>As a perhaps preferred alternative, students may wish to perform all (Python) programming computations using a free cloud-based account (i.e., Google Colab), which will be discussed and established at the beginning of the semester. Large-scale deep learning computations necessary for the final \u201cmini-project\u201d will utilize these resources.</p> <p>Note</p> <p>The Required University Policy Statements were provided in the original PDF of the course description.  They have been removed to allow the generative AI tools to focus on the concept enumeration.</p>"},{"location":"feedback/","title":"Feedback on Graph Data Modeling","text":"<p>You are welcome to connect with me on anytime on LinkedIn or submit any issues to GitHub Issue Log.  All pull-requests with fixes to errors or additions are always welcome.</p> <p>If you would like to fill out a short survey and give us ideas on how we can create better tools for intelligent textbooks in the future.</p>"},{"location":"glossary/","title":"Glossary of Terms","text":"<p>Below is an alphabetical glossary of 200 key concepts, each defined according to ISO 11179 guidelines. When relevant, an example of how the term is used in a Deep Learning context is provided.  A term definition is considered to be consistent with ISO metadata registry guideline 11179 if it meets the following criteria:</p> <ol> <li>Precise</li> <li>Concise</li> <li>Distinct</li> <li>Non-circular</li> <li>Unencumbered with business rules</li> </ol>"},{"location":"glossary/#accuracy","title":"Accuracy","text":"<p>A performance metric that measures the proportion of correct predictions out of all predictions made by a model. Example: In a binary classification problem, accuracy is the ratio of true positives and true negatives to the total sample size.</p>"},{"location":"glossary/#activation-functions","title":"Activation Functions","text":"<p>Mathematical functions applied to neuron outputs that introduce non-linearity into a neural network. Example: ReLU and Sigmoid are common activation functions used to help networks learn complex patterns.</p>"},{"location":"glossary/#actor-critic","title":"Actor-Critic","text":"<p>A class of reinforcement learning algorithms that maintain both a policy (actor) and a value function (critic) to guide action selection. Example: The actor-critic approach is used to stabilize training by combining policy gradient methods with value-based techniques.</p>"},{"location":"glossary/#adagrad","title":"AdaGrad","text":"<p>An adaptive gradient algorithm that individually scales learning rates based on the historical gradient magnitudes for each parameter. Example: AdaGrad can help train models more efficiently in scenarios where some parameters require more frequent updates than others.</p>"},{"location":"glossary/#adam-optimizer","title":"Adam Optimizer","text":"<p>An optimization algorithm that combines ideas from momentum (exponential moving averages of gradients) and AdaGrad (adaptive learning rates). Example: Adam is often the default choice for training deep neural networks due to its speed and stable convergence properties.</p>"},{"location":"glossary/#adversarial-examples","title":"Adversarial Examples","text":"<p>Inputs to a model that have been intentionally crafted to cause incorrect predictions, despite appearing normal to humans. Example: Slightly perturbed images that force a well-trained image classifier to misclassify a stop sign as a yield sign.</p>"},{"location":"glossary/#agile-methods","title":"Agile Methods","text":"<p>Project management practices emphasizing iterative development, collaboration, and adaptability. Example: In a machine learning project, sprints are used to rapidly prototype models and incorporate stakeholder feedback.</p>"},{"location":"glossary/#ai-branches","title":"AI Branches","text":"<p>Various subfields of Artificial Intelligence, including symbolic AI, data-driven AI, evolutionary computation, and others. Example: A course might compare symbolic reasoning systems with modern deep learning architectures.</p>"},{"location":"glossary/#ai-definition","title":"AI Definition","text":"<p>The study and development of machines capable of performing tasks that typically require human intelligence. Example: AI encompasses problem-solving, perception, language understanding, and learning processes.</p>"},{"location":"glossary/#automl","title":"AutoML","text":"<p>Automated Machine Learning techniques that handle tasks such as model selection, hyperparameter tuning, and feature engineering with minimal human intervention. Example: Tools like Google AutoML or AutoKeras can automatically try multiple pipelines and present the best-performing model.</p>"},{"location":"glossary/#autoencoder-dr","title":"Autoencoder DR","text":"<p>Dimensionality reduction technique that uses an autoencoder neural network to learn a compressed representation of data. Example: An autoencoder might reduce a 1000-dimensional dataset down to 50 dimensions for visualization.</p>"},{"location":"glossary/#autoencoders-ae","title":"Autoencoders (AE)","text":"<p>Neural network architectures designed to learn a compressed representation (encoding) of input data, then reconstruct it (decoding). Example: AEs are used to denoise images or perform feature extraction for anomaly detection.</p>"},{"location":"glossary/#autonomous-driving","title":"Autonomous Driving","text":"<p>The application of AI/ML methods to enable vehicles to sense their environment and operate without human intervention. Example: Deep neural networks can process camera and lidar data in real-time for self-driving car navigation.</p>"},{"location":"glossary/#auc-roc","title":"AUC-ROC","text":"<p>A performance metric summarizing the trade-off between true positive rate and false positive rate across different thresholds. Example: The area under the ROC curve (AUC) is often used to compare classifiers independent of a specific decision threshold.</p>"},{"location":"glossary/#backprop-through-time-bptt","title":"Backprop Through Time (BPTT)","text":"<p>A method for training recurrent neural networks by unrolling the network for a certain number of timesteps and applying backpropagation. Example: LSTM networks rely on BPTT to learn dependencies in sequential data such as text or time series.</p>"},{"location":"glossary/#backpropagation","title":"Backpropagation","text":"<p>The algorithm used to calculate gradients of error with respect to each weight in a neural network, enabling efficient training. Example: During backprop, partial derivatives of the loss function are propagated backward to update model parameters.</p>"},{"location":"glossary/#baseline-algorithms","title":"Baseline Algorithms","text":"<p>Simple or well-understood methods used as reference points for performance comparison. Example: A linear regression might serve as a baseline for a more complex deep model on a regression task.</p>"},{"location":"glossary/#batch-normalization","title":"Batch Normalization","text":"<p>A technique to normalize intermediate layer outputs to accelerate training and stabilize learning in neural networks. Example: By normalizing activations, batch norm helps reduce internal covariate shift.</p>"},{"location":"glossary/#batch-training","title":"Batch Training","text":"<p>A training paradigm where the model parameters are updated after processing an entire batch of training examples. Example: Large datasets are often split into batches to efficiently utilize GPU memory.</p>"},{"location":"glossary/#batchnorm","title":"BatchNorm","text":"<p>Another name for batch normalization, focusing on normalizing activations per mini-batch. Example: \u201cBatchNorm\u201d layers are common in architectures like ResNet and Inception.</p>"},{"location":"glossary/#bayesian-optimization","title":"Bayesian Optimization","text":"<p>A global optimization strategy using Bayesian inference to intelligently sample hyperparameters and find optimal configurations. Example: Given a function that\u2019s expensive to evaluate (e.g., a deep network training loop), Bayesian optimization tries to minimize the total evaluations required.</p>"},{"location":"glossary/#bert-overview","title":"BERT Overview","text":"<p>Description of Bidirectional Encoder Representations from Transformers, a popular transformer-based NLP model that learns context in both directions. Example: BERT is used to improve tasks like question-answering and sentence classification.</p>"},{"location":"glossary/#bias-mitigation","title":"Bias Mitigation","text":"<p>Techniques to reduce or remove unwanted bias in AI models, ensuring fair and equitable outcomes. Example: Reweighting training data to address underrepresentation of certain groups.</p>"},{"location":"glossary/#bias-variance-tradeoff","title":"Bias-Variance Tradeoff","text":"<p>The balance between the accuracy of a model (bias) and its sensitivity to small fluctuations in the training set (variance). Example: A highly complex model might overfit (low bias, high variance), while a simple model might underfit (high bias, low variance).</p>"},{"location":"glossary/#biological-inspiration","title":"Biological Inspiration","text":"<p>The design of AI techniques based on biological systems or processes, such as neural networks modeled after the human brain. Example: Convolutional neural networks are partially inspired by the visual cortex in mammals.</p>"},{"location":"glossary/#bleu-score","title":"BLEU Score","text":"<p>Bilingual Evaluation Understudy; a metric used to evaluate the quality of machine-translated text against reference translations. Example: BLEU is commonly reported in NLP tasks such as neural machine translation experiments.</p>"},{"location":"glossary/#capsule-networks","title":"Capsule Networks","text":"<p>Neural architectures that group neurons into \u201ccapsules\u201d to better capture positional and hierarchical relationships in data. Example: Capsule networks aim to preserve spatial relationships more effectively than traditional CNNs.</p>"},{"location":"glossary/#chatgpt-concept","title":"ChatGPT Concept","text":"<p>A high-level idea of OpenAI\u2019s ChatGPT, which uses large language models to generate context-aware text responses. Example: Students explore ChatGPT\u2019s approach to answer generation and how it leverages conversational context.</p>"},{"location":"glossary/#cloud-services","title":"Cloud Services","text":"<p>Remote computing resources (servers, storage, APIs) for hosting, training, and deploying AI models. Example: AWS, Azure, and Google Cloud offer GPU/TPU instances to accelerate model training.</p>"},{"location":"glossary/#cnn-architectures","title":"CNN Architectures","text":"<p>Convolutional Neural Network designs specialized for handling spatial data such as images. Example: Classic architectures include LeNet, AlexNet, VGG, ResNet, and DenseNet.</p>"},{"location":"glossary/#code-review","title":"Code Review","text":"<p>The process of examining and discussing code changes to improve code quality and share knowledge within a team. Example: Before merging new data preprocessing scripts, peers review for correctness and maintainability.</p>"},{"location":"glossary/#computer-vision","title":"Computer Vision","text":"<p>A field of AI focusing on enabling machines to interpret and understand visual information from the world. Example: Tasks include image classification, object detection, and image segmentation.</p>"},{"location":"glossary/#conditional-gan","title":"Conditional GAN","text":"<p>A GAN variant where both the generator and discriminator receive additional context information, such as class labels. Example: Conditional GANs can generate images conditioned on textual descriptions like \u201ccats\u201d or \u201cdogs.\u201d</p>"},{"location":"glossary/#confusion-matrix","title":"Confusion Matrix","text":"<p>A tabular layout displaying the number of correct and incorrect predictions grouped by class. Example: Rows typically represent actual classes, while columns represent predicted classes, making misclassifications visible.</p>"},{"location":"glossary/#conda-environment","title":"Conda Environment","text":"<p>A virtual environment manager provided by Anaconda, allowing users to isolate Python packages and dependencies. Example: Students create a separate conda environment to manage a specific ML project\u2019s libraries without interfering with system Python.</p>"},{"location":"glossary/#convolution-operation","title":"Convolution Operation","text":"<p>A mathematical operation where a filter (kernel) is applied to input data (e.g., an image) to detect features. Example: In CNNs, convolution layers learn filters that activate in response to relevant patterns.</p>"},{"location":"glossary/#cross-validation","title":"Cross-Validation","text":"<p>A technique for evaluating model performance by partitioning data into multiple folds, cycling through training and validation sets. Example: k-fold cross-validation helps assess how well the model generalizes to unseen data.</p>"},{"location":"glossary/#cyclegan","title":"CycleGAN","text":"<p>A GAN-based architecture for unpaired image-to-image translation. Example: CycleGAN can transform horse images into zebra images without needing paired training examples.</p>"},{"location":"glossary/#data-acquisition","title":"Data Acquisition","text":"<p>The process of gathering relevant datasets from various sources, such as APIs, sensors, or public repositories. Example: In a project, data acquisition might involve scraping websites or querying a medical imaging database.</p>"},{"location":"glossary/#data-annotation","title":"Data Annotation","text":"<p>Labeling or tagging raw data (images, text, audio) with meaningful information to facilitate supervised learning. Example: Crowdworkers often annotate bounding boxes on images to prepare object detection datasets.</p>"},{"location":"glossary/#data-augmentation","title":"Data Augmentation","text":"<p>Techniques used to increase the diversity of a training set by applying transformations (e.g., flips, rotations) to existing samples. Example: Randomly flipping or cropping images to help CNNs generalize better.</p>"},{"location":"glossary/#data-cleaning","title":"Data Cleaning","text":"<p>The process of identifying and correcting incomplete, inaccurate, or irrelevant parts of a dataset. Example: Removing duplicates or fixing inconsistent labels in a CSV file before model training.</p>"},{"location":"glossary/#data-driven-ai","title":"Data-Driven AI","text":"<p>AI methodologies that rely heavily on large datasets and statistical learning rather than explicit symbolic rules. Example: Deep learning is a classic form of data-driven AI, requiring abundant labeled data for training.</p>"},{"location":"glossary/#data-ethics","title":"Data Ethics","text":"<p>The standards and principles guiding the responsible collection, storage, and use of data. Example: Ensuring personal data is handled with user consent and compliance with legal frameworks such as GDPR.</p>"},{"location":"glossary/#data-imbalance","title":"Data Imbalance","text":"<p>A condition where classes or categories in a dataset are not equally represented. Example: In fraud detection, \u201cfraud\u201d cases are often far fewer than \u201cnon-fraud\u201d cases, impacting model training.</p>"},{"location":"glossary/#data-parallelism","title":"Data Parallelism","text":"<p>Distributing subsets of the input data across multiple processors or machines to train a model faster. Example: Large mini-batches are split across GPUs, and gradients are aggregated at each step.</p>"},{"location":"glossary/#data-preprocessing","title":"Data Preprocessing","text":"<p>Preparatory steps taken on raw data, such as cleaning, normalization, or encoding. Example: Converting categorical variables into one-hot vectors or normalizing images to zero mean and unit variance.</p>"},{"location":"glossary/#data-splits","title":"Data Splits","text":"<p>Partitioning data into subsets (e.g., training, validation, test) for model development and evaluation. Example: 80% of the data for training, 10% for validation, 10% for testing.</p>"},{"location":"glossary/#data-visualization","title":"Data Visualization","text":"<p>Graphical representation of data to reveal patterns, trends, or outliers. Example: Creating scatter plots in Matplotlib to explore relationships between features.</p>"},{"location":"glossary/#data-visualization-tools","title":"Data Visualization Tools","text":"<p>Software libraries and platforms that facilitate the creation of charts, graphs, and interactive plots. Example: Matplotlib, Seaborn, and Plotly are used in notebooks to illustrate key data insights.</p>"},{"location":"glossary/#deep-architecture","title":"Deep Architecture","text":"<p>Neural network designs featuring multiple hidden layers, enabling hierarchical feature extraction. Example: A typical deep architecture might have a dozen or more layers in a CNN.</p>"},{"location":"glossary/#deep-q-network-dqn","title":"Deep Q-Network (DQN)","text":"<p>A reinforcement learning approach where a deep neural network approximates the Q-function for action selection. Example: DQN was famously applied by DeepMind to play Atari games at a superhuman level.</p>"},{"location":"glossary/#densenet","title":"DenseNet","text":"<p>A CNN architecture where each layer is connected to every other layer in a feed-forward manner. Example: DenseNet alleviates the vanishing gradient problem by encouraging feature reuse.</p>"},{"location":"glossary/#depth-vs-width","title":"Depth Vs Width","text":"<p>The tradeoff between making a network deeper (more layers) or wider (more neurons per layer). Example: Deeper networks can learn more abstract features, whereas wider networks can capture more detail at each level.</p>"},{"location":"glossary/#denoising-diffusion","title":"Denoising Diffusion","text":"<p>A class of generative models where noise is incrementally added to data, then learned in reverse to generate samples. Example: Used in image generation tasks to progressively refine noise into realistic images.</p>"},{"location":"glossary/#diffusion-models","title":"Diffusion Models","text":"<p>Probabilistic models that learn to reverse a gradual noising process to produce new samples. Example: DALL\u00b7E 2 incorporates diffusion methods for high-quality image synthesis.</p>"},{"location":"glossary/#dimensionality-concepts","title":"Dimensionality Concepts","text":"<p>Principles and considerations related to the number of features or variables in a dataset (dimensionality). Example: High-dimensional data can be more difficult to visualize and may require techniques like PCA.</p>"},{"location":"glossary/#documentation","title":"Documentation","text":"<p>Written guides, explanations, or references describing software or processes. Example: Thorough documentation ensures that future team members can understand the codebase and its usage.</p>"},{"location":"glossary/#drug-discovery","title":"Drug Discovery","text":"<p>The application of AI to identify potential new medications by analyzing large chemical and biological datasets. Example: ML models predict molecular binding affinities to reduce trial-and-error in drug design.</p>"},{"location":"glossary/#dropout","title":"Dropout","text":"<p>A regularization method that randomly \u201cdrops\u201d or sets some neurons to zero during training to reduce overfitting. Example: Setting a 50% dropout rate in a dense layer to encourage robust feature learning.</p>"},{"location":"glossary/#early-stopping","title":"Early Stopping","text":"<p>A regularization technique that halts training when validation performance stops improving. Example: Prevents overfitting by not allowing the model to train excessively on one dataset.</p>"},{"location":"glossary/#edge-deployment","title":"Edge Deployment","text":"<p>Running AI models directly on edge devices (smartphones, IoT devices) rather than on centralized servers. Example: A small CNN for object recognition deployed on a mobile phone for real-time inference.</p>"},{"location":"glossary/#energy-based-models","title":"Energy-Based Models","text":"<p>A class of probabilistic models that define an energy function over configurations, and learning involves shaping this energy landscape. Example: Boltzmann machines are one type of energy-based model used for representation learning.</p>"},{"location":"glossary/#evaluation-metrics","title":"Evaluation Metrics","text":"<p>Quantitative measures to assess model performance, guiding model selection and tuning. Example: Accuracy, precision, recall, and F1 score are common metrics for classification tasks.</p>"},{"location":"glossary/#explainable-ai-xai","title":"Explainable AI (XAI)","text":"<p>Methods designed to make AI system decisions interpretable by humans. Example: Feature attribution maps that highlight which parts of an image influenced a CNN\u2019s classification.</p>"},{"location":"glossary/#exploration-vs-exploitation","title":"Exploration Vs Exploitation","text":"<p>The balance in reinforcement learning between trying new actions (exploration) and using known rewarding actions (exploitation). Example: An RL agent might explore different states early on, then exploit the best actions discovered.</p>"},{"location":"glossary/#exploding-gradient-control","title":"Exploding Gradient Control","text":"<p>Techniques to prevent gradients from becoming excessively large during backpropagation. Example: Gradient clipping is a common way to avoid unstable updates in RNN training.</p>"},{"location":"glossary/#exploding-gradients","title":"Exploding Gradients","text":"<p>A situation where gradients grow uncontrollably during training, causing large parameter updates and potential instability. Example: Deep RNNs may experience exploding gradients unless special measures (like clipping) are applied.</p>"},{"location":"glossary/#f1-score","title":"F1 Score","text":"<p>The harmonic mean of precision and recall, providing a single measure of a test\u2019s accuracy. Example: Used when you care about both false positives and false negatives in an imbalanced classification.</p>"},{"location":"glossary/#fairness","title":"Fairness","text":"<p>The principle of designing AI systems to avoid discriminatory outcomes or biased treatment. Example: Ensuring loan approval models do not systematically disadvantage applicants from certain demographics.</p>"},{"location":"glossary/#feature-engineering","title":"Feature Engineering","text":"<p>The process of creating or transforming input features to improve model performance. Example: Combining multiple text columns into a single normalized \u201cbag of words\u201d vector.</p>"},{"location":"glossary/#feature-space","title":"Feature Space","text":"<p>The multidimensional space where each dimension corresponds to a feature of the data. Example: Visualizing points in feature space helps understand how the model separates classes.</p>"},{"location":"glossary/#filters-and-kernels","title":"Filters And Kernels","text":"<p>Learnable convolution operators that detect features in images or other spatial data. Example: Early layers might learn edge detectors, while deeper layers capture more complex patterns.</p>"},{"location":"glossary/#financial-forecasting","title":"Financial Forecasting","text":"<p>Using AI/ML to predict market movements, asset prices, or economic indicators. Example: LSTM networks analyzing historical stock data for next-day price predictions.</p>"},{"location":"glossary/#flow-based-models","title":"Flow-Based Models","text":"<p>Generative models that transform noise into data samples via a series of invertible transformations. Example: RealNVP or Glow architectures produce exact likelihood estimates and allow sampling.</p>"},{"location":"glossary/#forward-propagation","title":"Forward Propagation","text":"<p>The process of passing input data through a neural network to get an output prediction. Example: In a feedforward network, data flows from the input layer through hidden layers to the output.</p>"},{"location":"glossary/#fully-connected-layers","title":"Fully Connected Layers","text":"<p>Layers where every neuron is connected to every neuron in the next layer, typically appearing after convolution blocks. Example: After convolution and pooling, the extracted features might go into a fully connected classifier.</p>"},{"location":"glossary/#gan-basics","title":"GAN Basics","text":"<p>The foundational idea of Generative Adversarial Networks, involving a generator and a discriminator in a minimax game. Example: A generator tries to create realistic images, while the discriminator attempts to distinguish them from real images.</p>"},{"location":"glossary/#generative-models","title":"Generative Models","text":"<p>Models that learn the joint probability distribution of data, enabling them to generate new, synthetic samples. Example: Models like GANs, VAEs, and diffusion models can create realistic images or text.</p>"},{"location":"glossary/#generator-vs-discriminator","title":"Generator Vs Discriminator","text":"<p>Two components of a GAN: the generator synthesizes data, and the discriminator classifies whether data is real or generated. Example: Training alternates between improving the generator\u2019s realism and tightening the discriminator\u2019s detection.</p>"},{"location":"glossary/#gpt-overview","title":"GPT Overview","text":"<p>Highlights of the Generative Pre-trained Transformer series, focusing on autoregressive language modeling at scale. Example: GPT-3 can generate coherent paragraphs of text based on a given prompt.</p>"},{"location":"glossary/#graph-neural-networks-gnns","title":"Graph Neural Networks (GNNs)","text":"<p>Networks designed to process graph-structured data, learning node or edge representations through message passing. Example: GNNs can predict molecular properties by treating atoms as nodes and bonds as edges.</p>"},{"location":"glossary/#gradient-descent","title":"Gradient Descent","text":"<p>An iterative optimization method that updates parameters in the opposite direction of the gradient of the loss function. Example: Simple gradient descent uses the entire dataset to compute gradients each iteration.</p>"},{"location":"glossary/#gru-units","title":"GRU Units","text":"<p>Gated Recurrent Unit cells that manage hidden state transitions without a separate cell state. Example: GRUs are often computationally simpler yet comparable to LSTMs for sequence tasks.</p>"},{"location":"glossary/#grid-search","title":"Grid Search","text":"<p>A hyperparameter tuning method that exhaustively tries every combination of a specified parameter grid. Example: Searching over different learning rates and regularization strengths for logistic regression.</p>"},{"location":"glossary/#gpu-acceleration","title":"GPU Acceleration","text":"<p>Utilizing graphics processing units to speed up parallelizable operations in neural network training. Example: Matrix multiplications in backprop are greatly accelerated on GPUs.</p>"},{"location":"glossary/#he-initialization","title":"He Initialization","text":"<p>Weight initialization method adapted for ReLU-like activation functions, aiming to maintain variance across layers. Example: Also known as Kaiming initialization, used to stabilize training in deep ReLU networks.</p>"},{"location":"glossary/#high-dimensional-data","title":"High-Dimensional Data","text":"<p>Data with many features, which can lead to the \u201ccurse of dimensionality\u201d and sparse observations in feature space. Example: Text data with thousands of unique terms is inherently high-dimensional.</p>"},{"location":"glossary/#history-of-ai","title":"History Of AI","text":"<p>The chronological development and milestones of AI, from symbolic systems to modern deep learning breakthroughs. Example: Tracing from early logic-based AI in the 1950s to recent achievements in large-scale neural models.</p>"},{"location":"glossary/#hyperparameter-tuning","title":"Hyperparameter Tuning","text":"<p>The process of finding optimal values for parameters not directly learned during training, like learning rates or layer sizes. Example: Using cross-validation to compare multiple hyperparameter configurations.</p>"},{"location":"glossary/#imagenet","title":"ImageNet","text":"<p>A large-scale image dataset widely used as a benchmark for deep learning, especially in computer vision. Example: Models that excel on ImageNet often generalize well to a range of vision tasks.</p>"},{"location":"glossary/#inception-modules","title":"Inception Modules","text":"<p>Architectural blocks that perform convolutions of different sizes in parallel, then concatenate outputs. Example: GoogLeNet (Inception v1) introduced inception modules for more efficient resource usage.</p>"},{"location":"glossary/#initialization-methods","title":"Initialization Methods","text":"<p>Techniques for setting initial weight values in neural networks to aid stable convergence. Example: He or Xavier initialization is often chosen based on the activation function used.</p>"},{"location":"glossary/#jupyter-notebooks","title":"Jupyter Notebooks","text":"<p>Interactive web-based computational tools that combine code, visualizations, and text. Example: Commonly used in teaching ML, allowing students to experiment step by step and visualize results.</p>"},{"location":"glossary/#key-figures","title":"Key Figures","text":"<p>Influential researchers or pioneers in AI who contributed foundational theories or breakthroughs. Example: Alan Turing, Marvin Minsky, Geoffrey Hinton, Yoshua Bengio, and Yann LeCun.</p>"},{"location":"glossary/#language-modeling","title":"Language Modeling","text":"<p>Predicting the likelihood of a sequence of words, forming the basis for many NLP tasks. Example: A language model might predict the next word in a sentence or evaluate the fluency of generated text.</p>"},{"location":"glossary/#large-language-models-llms","title":"Large Language Models (LLMs)","text":"<p>Very large neural network-based models trained on massive text corpora to perform complex language tasks. Example: GPT-3, BERT, and PaLM can perform text generation, question answering, and zero-shot tasks.</p>"},{"location":"glossary/#latent-space","title":"Latent Space","text":"<p>The lower-dimensional internal representation of data learned by a model, especially in generative methods. Example: In a VAE, points in the latent space can be sampled and decoded into new images.</p>"},{"location":"glossary/#layer-stacking","title":"Layer Stacking","text":"<p>Arranging multiple layers in a network to build deeper models capable of complex feature extraction. Example: Adding layers in a CNN to capture higher-level abstractions of the input.</p>"},{"location":"glossary/#learning-rate","title":"Learning Rate","text":"<p>A hyperparameter controlling the step size in gradient-based optimization. Example: A learning rate that\u2019s too high might overshoot minima, while one that\u2019s too low could prolong training.</p>"},{"location":"glossary/#learning-rate-scheduling","title":"Learning Rate Scheduling","text":"<p>Strategies to adjust the learning rate over time, typically reducing it as training progresses. Example: Step decay, exponential decay, and warm restarts are all scheduling techniques.</p>"},{"location":"glossary/#lime","title":"LIME","text":"<p>Local Interpretable Model-agnostic Explanations; explains predictions of any classifier by approximating it locally with an interpretable model. Example: LIME can highlight text snippets that most influenced a sentiment classifier\u2019s decision.</p>"},{"location":"glossary/#lstm-units","title":"LSTM Units","text":"<p>Long Short-Term Memory cells that maintain and control access to an internal cell state for long-range dependencies in sequences. Example: LSTMs are popular in NLP for capturing context across lengthy texts.</p>"},{"location":"glossary/#likelihood-estimation","title":"Likelihood Estimation","text":"<p>The process of determining parameters of a probabilistic model by maximizing the likelihood of observed data. Example: In generative models, training often involves maximizing log-likelihood.</p>"},{"location":"glossary/#local-minima","title":"Local Minima","text":"<p>Points in the loss landscape where no small move decreases the loss, but they may not be the global optimum. Example: Neural networks often rely on large parameter spaces that can have many local minima.</p>"},{"location":"glossary/#loss-functions","title":"Loss Functions","text":"<p>Mathematical functions quantifying the difference between predictions and targets, guiding parameter updates. Example: Mean Squared Error is a loss function for regression; Cross-Entropy is common for classification.</p>"},{"location":"glossary/#loss-surface","title":"Loss Surface","text":"<p>The multidimensional space defined by network parameters on which the loss function value is plotted. Example: Gradient descent methods navigate the loss surface to find minima.</p>"},{"location":"glossary/#manifold-hypothesis","title":"Manifold Hypothesis","text":"<p>The assumption that high-dimensional data points lie on lower-dimensional manifolds embedded in the input space. Example: Techniques like t-SNE or UMAP attempt to uncover these manifolds for visualization.</p>"},{"location":"glossary/#markov-decision-process-mdp","title":"Markov Decision Process (MDP)","text":"<p>A mathematical framework for sequential decision-making, characterized by states, actions, rewards, and transition probabilities. Example: Reinforcement learning often models environments as MDPs for algorithmic exploration.</p>"},{"location":"glossary/#matplotlib-basics","title":"Matplotlib Basics","text":"<p>Fundamental features of Matplotlib, a Python library for creating static, animated, and interactive visualizations. Example: Plotting histograms, line graphs, and scatter plots to understand dataset distributions.</p>"},{"location":"glossary/#mean-squared-error-mse","title":"Mean Squared Error (MSE)","text":"<p>A regression loss function that averages the squared differences between predictions and targets. Example: MSE is minimized during training of linear regression or certain autoencoders.</p>"},{"location":"glossary/#medical-imaging","title":"Medical Imaging","text":"<p>The application of AI to interpret and analyze medical scans such as MRIs, CTs, and X-rays. Example: CNNs detecting tumors in MRI scans to assist radiologists.</p>"},{"location":"glossary/#memory-management","title":"Memory Management","text":"<p>Techniques to efficiently allocate and handle data in GPU/CPU memory during model training. Example: Gradient checkpointing helps reduce memory usage in very deep networks.</p>"},{"location":"glossary/#mini-batch-training","title":"Mini-Batch Training","text":"<p>A compromise between batch and stochastic training, updating parameters after a small subset of samples. Example: Common in practice for balancing computational efficiency with stable gradient estimates.</p>"},{"location":"glossary/#ml-definition","title":"ML Definition","text":"<p>A subfield of AI that focuses on algorithms learning patterns from data rather than being explicitly programmed. Example: Classification and regression tasks where models improve their performance as they process more data.</p>"},{"location":"glossary/#mlops","title":"MLOps","text":"<p>A set of practices for deploying and maintaining machine learning models in production, analogous to DevOps. Example: Automated CI/CD pipelines that retrain and redeploy models as new data arrives.</p>"},{"location":"glossary/#model-compression","title":"Model Compression","text":"<p>Techniques to reduce model size and inference costs, such as pruning, quantization, or knowledge distillation. Example: Compressing a large CNN so it can run on edge devices with limited memory.</p>"},{"location":"glossary/#model-interpretability","title":"Model Interpretability","text":"<p>The clarity with which a human can understand a model\u2019s internal processes and decisions. Example: Using saliency maps to see which pixels in an image were key for a CNN\u2019s classification.</p>"},{"location":"glossary/#model-parallelism","title":"Model Parallelism","text":"<p>Splitting a model\u2019s layers or parameters across different computational units. Example: Large language models can be distributed across multiple GPUs, each storing only part of the network.</p>"},{"location":"glossary/#momentum-optimizer","title":"Momentum Optimizer","text":"<p>An extension of gradient descent that accumulates velocity from past updates to damp oscillations and accelerate learning. Example: Typically combined with a learning rate schedule to converge faster.</p>"},{"location":"glossary/#multi-layer-perceptron","title":"Multi-Layer Perceptron","text":"<p>A fully connected feedforward network with one or more hidden layers. Example: Often used as a baseline for tabular data classification or regression tasks.</p>"},{"location":"glossary/#natural-language-processing-nlp","title":"Natural Language Processing (NLP)","text":"<p>AI techniques enabling machines to understand, interpret, and generate human language. Example: Chatbots, machine translation, and sentiment analysis are common NLP applications.</p>"},{"location":"glossary/#neural-machine-translation","title":"Neural Machine Translation","text":"<p>An approach to automated translation that uses deep neural networks, often encoder-decoder architectures. Example: Systems like Google Translate or DeepL rely on neural machine translation to handle multiple languages.</p>"},{"location":"glossary/#nn-origins","title":"NN Origins","text":"<p>The historical foundation of neural networks, tracing back to early perceptron models and Hebbian learning. Example: The perceptron\u2019s creation in the 1950s laid groundwork for modern deep learning.</p>"},{"location":"glossary/#nobel-prizes","title":"Nobel Prizes","text":"<p>Prestigious awards that, while not commonly granted specifically for AI, have occasionally been given for foundational contributions relevant to AI fields. Example: John Nash\u2019s work in game theory influenced multi-agent AI, recognized with a Nobel in Economics.</p>"},{"location":"glossary/#nonlinear-embeddings","title":"Nonlinear Embeddings","text":"<p>Mapping high-dimensional data into a lower-dimensional space using nonlinear transformations. Example: t-SNE and UMAP produce nonlinear embeddings to visualize clusters.</p>"},{"location":"glossary/#numpy-basics","title":"NumPy Basics","text":"<p>Core functionalities of the NumPy library for handling n-dimensional arrays and performing vectorized operations. Example: Creating and reshaping arrays, broadcasting, and using universal functions like <code>np.exp()</code>.</p>"},{"location":"glossary/#object-detection","title":"Object Detection","text":"<p>Identifying and localizing objects within images or video frames, typically returning bounding boxes and class labels. Example: A YOLO-based model scanning real-time video to detect pedestrians and vehicles.</p>"},{"location":"glossary/#overfitting-vs-underfitting","title":"Overfitting Vs Underfitting","text":"<p>Overfitting occurs when a model learns spurious details in the training data, while underfitting fails to capture underlying trends. Example: A deep network might overfit a small dataset; a simple linear model might underfit a complex dataset.</p>"},{"location":"glossary/#pca","title":"PCA","text":"<p>Principal Component Analysis; a linear dimensionality reduction method finding directions of maximum variance. Example: PCA can compress a 100-dimensional dataset into a handful of principal components for visualization.</p>"},{"location":"glossary/#pandas-basics","title":"Pandas Basics","text":"<p>Common operations in the Pandas library, such as DataFrame creation, cleaning, merging, and analysis. Example: Using <code>pandas.read_csv()</code> to load a dataset and <code>DataFrame.describe()</code> for summary statistics.</p>"},{"location":"glossary/#perceptron-model","title":"Perceptron Model","text":"<p>A single-layer linear classifier that outputs a binary decision based on a weighted sum of inputs. Example: Historically important as the earliest form of a neural network unit.</p>"},{"location":"glossary/#policy-gradient","title":"Policy Gradient","text":"<p>A family of RL algorithms that optimize a parameterized policy by ascending an estimate of the gradient of expected reward. Example: REINFORCE is a basic policy gradient method using sampled trajectories.</p>"},{"location":"glossary/#pooling-layers","title":"Pooling Layers","text":"<p>Layers that reduce spatial dimensions by combining nearby feature responses, helping control overfitting. Example: Max pooling or average pooling in a CNN to halve the width and height of feature maps.</p>"},{"location":"glossary/#positional-encoding","title":"Positional Encoding","text":"<p>A technique used in transformer architectures to inject information about sequence order without recurrence. Example: Sine and cosine functions of different frequencies are added to word embeddings in Transformers.</p>"},{"location":"glossary/#precision","title":"Precision","text":"<p>The fraction of predicted positives that are truly positive, measuring correctness among positive predictions. Example: High precision in a medical test means few healthy people are incorrectly diagnosed as sick.</p>"},{"location":"glossary/#pruning","title":"Pruning","text":"<p>Removing weights or neurons from a trained model to reduce complexity and size, often with minimal accuracy loss. Example: Pruning can eliminate near-zero weights, speeding up inference in production.</p>"},{"location":"glossary/#privacy","title":"Privacy","text":"<p>The right or requirement that individuals control their personal data and how it is used. Example: Differential privacy in ML ensures training data cannot be reverse-engineered from model parameters.</p>"},{"location":"glossary/#prompt-engineering","title":"Prompt Engineering","text":"<p>The practice of carefully designing prompts or instructions to guide large language models for desired outputs. Example: Providing explicit context and constraints in a GPT prompt to extract factual answers.</p>"},{"location":"glossary/#protein-folding","title":"Protein Folding","text":"<p>The computational prediction of a protein\u2019s 3D structure from its amino acid sequence, aided by AI breakthroughs. Example: DeepMind\u2019s AlphaFold made significant progress in accurately modeling protein configurations.</p>"},{"location":"glossary/#project-scoping","title":"Project Scoping","text":"<p>Defining the objectives, resources, and deliverables of a machine learning or AI project. Example: Determining the data needed, performance targets, and timeline for a sentiment analysis project.</p>"},{"location":"glossary/#pytorch-intro","title":"PyTorch Intro","text":"<p>An overview of the PyTorch deep learning framework, emphasizing its dynamic computation graph. Example: PyTorch\u2019s imperative style makes debugging simpler and is favored by many researchers.</p>"},{"location":"glossary/#python-setup","title":"Python Setup","text":"<p>Basic installation and configuration of Python environments, packages, and tools. Example: Installing Python 3.x, pip, and setting up a virtual environment on a workstation.</p>"},{"location":"glossary/#q-learning","title":"Q-Learning","text":"<p>A model-free RL algorithm that learns an action-value function predicting future rewards. Example: The algorithm updates a Q-table or Q-network using Bellman equations and experiences from the environment.</p>"},{"location":"glossary/#quantization","title":"Quantization","text":"<p>Reducing the precision of model parameters (e.g., from 32-bit floating-point to 8-bit integers) to improve efficiency. Example: Quantized networks often run faster on edge devices with limited compute power.</p>"},{"location":"glossary/#random-search","title":"Random Search","text":"<p>A hyperparameter tuning method selecting parameter combinations randomly within predefined ranges. Example: Often more efficient than grid search when the parameter space is large.</p>"},{"location":"glossary/#recall","title":"Recall","text":"<p>The fraction of actual positives correctly identified by the model, measuring completeness. Example: In a medical test, recall indicates the percentage of sick patients who are correctly diagnosed.</p>"},{"location":"glossary/#recommender-systems","title":"Recommender Systems","text":"<p>Algorithms designed to suggest items, such as products or media, to users based on preferences or similarities. Example: Matrix factorization or deep collaborative filtering for movie recommendations.</p>"},{"location":"glossary/#regression-vs-classification","title":"Regression Vs Classification","text":"<p>Distinguishes between predicting a continuous value (regression) and predicting a discrete label (classification). Example: House price prediction is regression, while determining spam vs non-spam email is classification.</p>"},{"location":"glossary/#regularization-overview","title":"Regularization Overview","text":"<p>Techniques (like weight decay, dropout) that constrain model complexity to prevent overfitting. Example: Adding L2 regularization to a neural network\u2019s cost function penalizes large weights.</p>"},{"location":"glossary/#requirement-analysis","title":"Requirement Analysis","text":"<p>Identifying the scope, constraints, and success criteria for an AI project before implementation. Example: Determining user needs, regulatory constraints, and performance thresholds for a medical imaging system.</p>"},{"location":"glossary/#residual-networks-resnet","title":"Residual Networks (ResNet)","text":"<p>Deep neural networks with skip connections that help mitigate vanishing gradients by enabling identity mappings. Example: ResNet-50 is a popular architecture for ImageNet classification tasks.</p>"},{"location":"glossary/#responsible-ai","title":"Responsible AI","text":"<p>AI development and deployment aligned with legal, ethical, and societal values. Example: Designing systems that respect user privacy, avoid bias, and are transparent.</p>"},{"location":"glossary/#reward-shaping","title":"Reward Shaping","text":"<p>Modifying or adding auxiliary rewards in RL to guide the agent toward desired behaviors. Example: Giving an agent a small reward for each time step it stays on track in a self-driving simulation.</p>"},{"location":"glossary/#rl-definition","title":"RL Definition","text":"<p>Reinforcement Learning is a subfield of AI where agents learn optimal behaviors through trial-and-error feedback from an environment. Example: An RL agent in a game environment receives rewards (scores) for achieving objectives.</p>"},{"location":"glossary/#robotics","title":"Robotics","text":"<p>The intersection of engineering and AI focusing on designing and controlling physical machines that perform tasks autonomously or semi-autonomously. Example: Automated robotic arms in manufacturing lines guided by computer vision.</p>"},{"location":"glossary/#scaling-and-normalization","title":"Scaling And Normalization","text":"<p>Rescaling features to standardized ranges or distributions for more stable training. Example: Applying min-max scaling to each feature so that all values lie between 0 and 1.</p>"},{"location":"glossary/#score-matching","title":"Score Matching","text":"<p>A technique for training generative models by matching the score function (gradient of log-density) of the model to that of the data. Example: Used in diffusion-based methods to iteratively denoise samples.</p>"},{"location":"glossary/#scipy-basics","title":"SciPy Basics","text":"<p>Fundamental capabilities of SciPy for scientific computations, including optimization, integration, and statistics. Example: Using <code>scipy.optimize</code> to implement advanced fitting procedures in an ML pipeline.</p>"},{"location":"glossary/#scikit-learn-overview","title":"Scikit-Learn Overview","text":"<p>Core features of the scikit-learn library, offering high-level APIs for classical ML algorithms, preprocessing, and validation. Example: Using <code>GridSearchCV</code> for hyperparameter tuning on a random forest model.</p>"},{"location":"glossary/#security","title":"Security","text":"<p>Protective measures ensuring AI systems resist unauthorized access, tampering, or malicious attacks. Example: Hardening model APIs against adversarial inputs that might reveal sensitive data.</p>"},{"location":"glossary/#self-attention","title":"Self-Attention","text":"<p>A mechanism in transformer models enabling each position in a sequence to attend to every other position for context. Example: BERT\u2019s self-attention layers capture dependencies in a sentence without relying on recurrence.</p>"},{"location":"glossary/#sequence-modeling","title":"Sequence Modeling","text":"<p>Approaches to handle sequential data (text, time series, etc.), capturing dependencies across timesteps. Example: LSTMs, GRUs, and Transformers are common sequence modeling architectures.</p>"},{"location":"glossary/#sequence-to-sequence","title":"Sequence-To-Sequence","text":"<p>Neural architectures mapping an input sequence (e.g., a sentence in English) to an output sequence (e.g., a sentence in French). Example: Used extensively in neural machine translation and speech recognition tasks.</p>"},{"location":"glossary/#shap","title":"SHAP","text":"<p>SHapley Additive exPlanations; a method based on Shapley values to interpret predictions by attributing contributions of each feature. Example: Generating a SHAP plot to see which features most influence a credit-scoring model\u2019s decisions.</p>"},{"location":"glossary/#skip-connections","title":"Skip Connections","text":"<p>Links that bypass one or more layers, helping gradients flow more easily in deep networks. Example: ResNet\u2019s skip connections add layer outputs directly to subsequent layers to mitigate vanishing gradients.</p>"},{"location":"glossary/#speech-recognition","title":"Speech Recognition","text":"<p>The task of converting spoken language into text using acoustic and language models. Example: Voice assistants transcribe user commands in real-time for further processing.</p>"},{"location":"glossary/#stochastic-training","title":"Stochastic Training","text":"<p>Updating model parameters after each individual sample or a small random subset (mini-batch). Example: Known as SGD, helps the model converge faster with more frequent updates.</p>"},{"location":"glossary/#stride-and-padding","title":"Stride And Padding","text":"<p>Parameters in convolution operations that determine how filters slide over input data and whether border regions are preserved. Example: Padding=\u201csame\u201d ensures output dimensions remain the same as input for certain CNN layers.</p>"},{"location":"glossary/#style-transfer","title":"Style Transfer","text":"<p>Neural technique that reworks the style of one image onto the content of another. Example: Merging a photo with the painting style of Van Gogh\u2019s \u201cStarry Night.\u201d</p>"},{"location":"glossary/#supervised-vs-unsupervised","title":"Supervised Vs Unsupervised","text":"<p>A distinction between learning with labeled data (supervised) vs. discovering patterns in unlabeled data (unsupervised). Example: Classifying labeled images is supervised; clustering unlabeled images is unsupervised.</p>"},{"location":"glossary/#symbolic-ai","title":"Symbolic AI","text":"<p>AI methods using explicit, human-readable representations of problems, logic, and rules. Example: Expert systems that encode domain knowledge in symbolic form.</p>"},{"location":"glossary/#team-collaboration","title":"Team Collaboration","text":"<p>Collective effort where multiple individuals share responsibilities and knowledge to complete AI projects. Example: Data engineers, data scientists, and software developers working together on a production pipeline.</p>"},{"location":"glossary/#t-sne","title":"t-SNE","text":"<p>t-Distributed Stochastic Neighbor Embedding; a non-linear dimensionality reduction method for visualization. Example: Often used to plot high-dimensional data (like embeddings) in 2D or 3D.</p>"},{"location":"glossary/#tensorflow-intro","title":"TensorFlow Intro","text":"<p>An overview of the TensorFlow framework emphasizing its computational graph, eager mode, and ecosystem tools. Example: Students build and train neural networks with Keras, a high-level TensorFlow API.</p>"},{"location":"glossary/#text-generation","title":"Text Generation","text":"<p>The task of producing coherent text sequences, often using language models. Example: GPT-based systems can generate paragraphs of natural-sounding text from a prompt.</p>"},{"location":"glossary/#text-generation-models","title":"Text Generation Models","text":"<p>Architectures specialized in producing novel text, typically via learned probability distributions over tokens. Example: LSTM-based decoders or transformer-based language models for writing summaries or creative content.</p>"},{"location":"glossary/#text-to-image","title":"Text-To-Image","text":"<p>Models that generate images based on textual input descriptions. Example: DALL\u00b7E variants produce custom images from user prompts like \u201can armchair shaped like an avocado.\u201d</p>"},{"location":"glossary/#time-series-forecasting","title":"Time-Series Forecasting","text":"<p>Techniques to predict future values of a sequence based on past observations. Example: LSTMs or Prophet library used for forecasting stock prices or energy demands.</p>"},{"location":"glossary/#training-validation-test","title":"Training-Validation-Test","text":"<p>Standard data splitting strategy: a training set for model fitting, a validation set for hyperparameter tuning, and a test set for final evaluation. Example: 60% train, 20% validation, 20% test split for a typical classification dataset.</p>"},{"location":"glossary/#transfer-learning-basics","title":"Transfer Learning Basics","text":"<p>Techniques for leveraging pre-trained models on new tasks with limited additional data. Example: Using a pre-trained ResNet on ImageNet as a feature extractor for a custom dataset.</p>"},{"location":"glossary/#tpu-acceleration","title":"TPU Acceleration","text":"<p>Using Tensor Processing Units (custom ASICs by Google) to speed up large-scale model training. Example: TPUs can be accessed on Google Cloud to train large transformer models more efficiently than GPUs.</p>"},{"location":"glossary/#umap","title":"UMAP","text":"<p>Uniform Manifold Approximation and Projection; a non-linear technique for dimensionality reduction. Example: Faster and often better at preserving global structure compared to t-SNE on large datasets.</p>"},{"location":"glossary/#value-functions","title":"Value Functions","text":"<p>In reinforcement learning, functions estimating expected future rewards from a given state (or state-action pair). Example: The critic in actor-critic algorithms learns a value function to guide the actor\u2019s updates.</p>"},{"location":"glossary/#vanilla-rnn","title":"Vanilla RNN","text":"<p>A basic recurrent neural network that uses hidden states to process sequences one step at a time. Example: Applied to simple sequence tasks but prone to vanishing/exploding gradient issues for long sequences.</p>"},{"location":"glossary/#vanishing-gradients","title":"Vanishing Gradients","text":"<p>A phenomenon where gradients diminish in magnitude through backprop, hindering learning in deep networks. Example: Sigmoid activations can exacerbate vanishing gradients as the network depth grows.</p>"},{"location":"glossary/#version-control","title":"Version Control","text":"<p>Systems that track changes to code over time, allowing collaboration and reversion if needed. Example: Git and GitHub store historical commits and manage parallel development branches.</p>"},{"location":"glossary/#version-control-workflow","title":"Version Control Workflow","text":"<p>Best practices and procedures for using version control systems, including branching, merging, and reviewing. Example: A feature branch workflow ensures code is tested and reviewed before merging into <code>main</code>.</p>"},{"location":"glossary/#variational-autoencoders-vae","title":"Variational Autoencoders (VAE)","text":"<p>Generative models that learn a latent distribution of data using an encoder-decoder framework with a KL-divergence term. Example: VAEs create smooth latent spaces, enabling interpolation between different generated samples.</p>"},{"location":"glossary/#vision-transformers-vit","title":"Vision Transformers (ViT)","text":"<p>Transformer-based architectures adapted for computer vision tasks by splitting images into patches. Example: ViT processes each patch as a token, leveraging self-attention for image classification.</p>"},{"location":"glossary/#weights-and-biases","title":"Weights And Biases","text":"<p>Trainable parameters in a neural network that transform inputs into outputs. Example: A linear layer with 10 inputs and 5 outputs would have 10\u00d75 weights plus 5 bias terms.</p>"},{"location":"glossary/#weight-decay","title":"Weight Decay","text":"<p>A regularization method applying an L2 penalty on weights to encourage smaller parameter values. Example: Often implemented as a parameter in optimizers like SGD or Adam (e.g., <code>weight_decay=1e-4</code>).</p>"},{"location":"glossary/#xavier-initialization","title":"Xavier Initialization","text":"<p>A weight initialization method maintaining variance in both forward and backward passes for certain activation functions. Example: Often used with tanh or sigmoid activations to keep gradients stable early in training.</p>"},{"location":"glossary/#text-to-image_1","title":"Text-to-Image","text":"<p>(Duplicate check \u2014 We already covered \"Text-To-Image\" at concept 110. Ensuring no duplication. It's already listed. We\u2019ll ignore any duplicates.)</p> <p>(No more new Z or Y terms, so we\u2019re done.)</p> <p>This completes the alphabetical glossary of all 200 concepts.</p>"},{"location":"how-we-built-this-site/","title":"How We Built This Site","text":"<p>This page describes how we built this website and some of  the rationale behind why we made various design choices.</p>"},{"location":"how-we-built-this-site/#python","title":"Python","text":"<p>MicroSims are about how we use generative AI to create animations and simulations.  The language of AI is Python.  So we wanted to create a site that could be easily understood by Python developers.</p>"},{"location":"how-we-built-this-site/#mkdocs-vs-docusaurus","title":"Mkdocs vs. Docusaurus","text":"<p>There are two main tools used by Python developers to write documentation: Mkdocs and Docusaurus.  Mkdocs is easier to use and more popular than Docusaurus. Docusaurus is also optimized for single-page applications. Mkdocs also has an extensive library of themes and plugins. None of us are experts in JavaScript or React. Based on our ChatGPT Analysis of the Tradeoffs we chose mkdocs for this site management.</p>"},{"location":"how-we-built-this-site/#github-and-github-pages","title":"GitHub and GitHub Pages","text":"<p>GitHub is a logical choice to store our  site source code and documentation.  GitHub also has a Custom GitHub Action that does auto-deployment if any files on the site change. We don't currently have this action enabled, but other teams can use this feature if they don't have the ability to do a local build with mkdocs.</p> <p>GitHub also has Issues,  Projects and releases that we can use to manage our bugs and tasks.</p> <p>The best practice for low-cost websites that have public-only content is GitHub Pages. Mkdocs has a command (<code>mkdocs gh-deploy</code>) that does deployment directly to GitHub Pages.  This was an easy choice to make.</p>"},{"location":"how-we-built-this-site/#github-clone","title":"GitHub Clone","text":"<p>If you would like to clone this repository, here are the commands:</p> <pre><code>mkdir projects\ncd projects\ngit clone https://github.com/dmccreary/microsims\n</code></pre>"},{"location":"how-we-built-this-site/#after-changes","title":"After Changes","text":"<p>After you make local changes you must do the following:</p> <pre><code># add the new files to a a local commit transaction\ngit add FILES\n# Execute the a local commit with a message about what and why you are doing the commit\ngit commit -m \"comment\"\n# Update the central GitHub repository\ngit push\n</code></pre>"},{"location":"how-we-built-this-site/#material-theme","title":"Material Theme","text":"<p>We had several options when picking a mkdocs theme:</p> <ol> <li>Mkdocs default</li> <li>Readthedocs</li> <li>Third-Party Themes See Ranking</li> </ol> <p>The Material Theme had 16K stars.  No other theme had over a few hundred. This was also an easy design decision.</p> <p>One key criterial was the social Open Graph tags so that when our users post a link to a simulation, the image of the simulation is included in the link.  Since Material supported this, we used the Material theme. You can see our ChatGPT Design Decision Analysis if you want to check our decision process.</p>"},{"location":"how-we-built-this-site/#enable-edit-icon","title":"Enable Edit Icon","text":"<p>To enable the Edit icon on all pages, you must add the edit_uri and the content.action.edit under the theme features area.</p> <pre><code>edit_uri: edit/master/docs/\n</code></pre> <pre><code>    theme:\n        features:\n            - content.action.edit\n</code></pre>"},{"location":"how-we-built-this-site/#conda-vs-venv","title":"Conda vs VENV","text":"<p>There are two choices for virtual environments.  We can use the native Python venv or use Conda.  venv is simle but is only designed for pure Python projects.  We imagine that this site could use JavaScript and other langauges in the future, so we picked Conda. There is nothing on this microsite that prevents you from using one or the other.  See the ChatGPT Analysis Here.</p> <p>Here is the conda script that we ran to create a new mkdocs environment that also supports the material social imaging libraries.</p> <pre><code>conda deactivate\nconda create -n mkdocs python=3\nconda activate mkdocs\npip install mkdocs \"mkdocs-material[imaging]\"\n</code></pre>"},{"location":"how-we-built-this-site/#mkdocs-commands","title":"Mkdocs Commands","text":"<p>There are three simple mkdoc commands we use.</p>"},{"location":"how-we-built-this-site/#local-build","title":"Local Build","text":"<pre><code>mkdocs build\n</code></pre> <p>This builds your website in a folder called <code>site</code>.  Use this to test that the mkdocs.yml site is working and does not have any errors.</p>"},{"location":"how-we-built-this-site/#run-a-local-server","title":"Run a Local Server","text":"<pre><code>mkdocs serve\n</code></pre> <p>This runs a server on <code>http://localhost:8000</code>. Use this to test the display formatting locally before you push your code up to the GitHub repo.</p> <pre><code>mkdoc gh-deploy\n</code></pre> <p>This pushes everything up to the GitHub Pages site. Note that it does not commit your code to GitHub.</p>"},{"location":"how-we-built-this-site/#mkdocs-material-social-tags","title":"Mkdocs Material Social Tags","text":"<p>We are using the Material Social tags.  This is a work in progress!</p> <p>Here is what we have learned.</p> <ol> <li>There are extensive image processing libraries that can't be installed with just pip.  You will need to run a tool like brew on the Mac to get the libraries installed.</li> <li>Even after <code>brew</code> installs the libraries, you have to get your environment to find the libraries.  The only way I could get that to work was to set up a local UNIX environment variable.</li> </ol> <p>Here is the brew command that I ran:</p> <pre><code>brew install cairo freetype libffi libjpeg libpng zlib\n</code></pre> <p>I then had to add the following to my ~/.zshrc file:</p> <pre><code>export DYLD_FALLBACK_LIBRARY_PATH=/opt/homebrew/lib\n</code></pre> <p>Note that I am running on a Mac with Apple silicon.  This means that the image libraries that brew downloads must be specific to the Mac Arm instruction set.</p>"},{"location":"how-we-built-this-site/#image-generation-and-compression","title":"Image Generation and Compression","text":"<p>I have used ChatGPT to create most of my images.  However, they are too large for most websites.  To compress them down I used  https://tinypng.com/ which is a free tool  for compressing png images without significant loss of quality.  The files created with ChatGPT are typically around 1-2 MB.  After  using the TinyPNG site the size is typically around 200-300KB.</p> <ul> <li>Cover images for blog post #4364</li> <li>Discussion on overriding the Social Card Image</li> </ul>"},{"location":"license/","title":"Creative Commons License","text":"<p>All content in this repository is governed by the following license agreement:</p>"},{"location":"license/#license-type","title":"License Type","text":"<p>Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0 DEED)</p>"},{"location":"license/#link-to-license-agreement","title":"Link to License Agreement","text":"<p>https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en</p>"},{"location":"license/#your-rights","title":"Your Rights","text":"<p>You are free to:</p> <ul> <li>Share \u2014 copy and redistribute the material in any medium or format</li> <li>Adapt \u2014 remix, transform, and build upon the material</li> </ul> <p>The licensor cannot revoke these freedoms as long as you follow the license terms.</p>"},{"location":"license/#restrictions","title":"Restrictions","text":"<ul> <li>Attribution \u2014 You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.</li> <li>NonCommercial \u2014 You may not use the material for commercial purposes.</li> <li>ShareAlike \u2014 If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.</li> <li>No additional restrictions \u2014 You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.</li> </ul> <p>Notices</p> <p>You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation.</p> <p>No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.</p> <p>This deed highlights only some of the key features and terms of the actual license. It is not a license and has no legal value. You should carefully review all of the terms and conditions of the actual license before using the licensed material.</p>"},{"location":"references/","title":"Site References","text":"<ol> <li>mkdocs - https://www.mkdocs.org/ - this is our tool for building the website.  It converts Markdown into HTML in the <code>site</code> directory.</li> <li>mkdocs material theme - https://squidfunk.github.io/mkdocs-material/ - this is the theme for our site.  The theme adds the user interface elements that give our site the look and feel.  It also has the features such as social cards.</li> <li>GitHub Pages - https://pages.github.com/ - this is the free tool for hosting public websites created by mkdocs</li> <li>Markdown - https://www.mkdocs.org/user-guide/writing-your-docs/#writing-with-markdown - this is the format we use for text.  It allows us to have headers, lists, tables, links and images without learning HTML.</li> <li>Deploy Mkdocs GitHub Action - https://github.com/marketplace/actions/deploy-mkdocs - this is the tool we use to automatically build our site after edits are checked in with Git.</li> <li>Git Book - https://git-scm.com/book/en/v2 - a useful book on Git.  Just read the first two chapters to learn how to check in new code.</li> <li>Conda - https://conda.io/ - this is a command line tool that keeps our Python libraries organized for each project.</li> <li>VS Code - https://code.visualstudio.com/ - this is the integrated development environment we use to mange the files on our website.</li> <li>Markdown Paste - https://marketplace.visualstudio.com/items?itemName=telesoho.vscode-markdown-paste-image - this is the VS code extension we use to make sure we keep the markdown format generated by ChatGPT.</li> </ol>"},{"location":"prompts/02-bloom-taxonomy-description/","title":"Bloom Taxonomy Description","text":"<p>Prompt</p> <p>Give the course description, apply the Bloom Taxonomy to rewrite the course description into a set of precise levels.</p> <p>Leverage Bloom\u2019s Taxonomy to structure the course, detailing the knowledge, skills, and applications students will develop at each cognitive level (remember, understand, apply, analyze, evaluate, and create).</p> <p>In the description, highlight how generative AI will serve as a primary teaching tool in the following ways:</p> <p>Metaphors and Analogies: Explain how generative AI will dynamically create metaphors that help students understand complex circuits and system concepts intuitively, for example, comparing [XXX] to [YYY] different contexts.</p> <p>Stories and Lessons: Illustrate how AI-generated narratives will guide students through historical milestones in circuit design, with characters like pioneering engineers or scientists to add context and enhance engagement.</p> <p>Content Generation: Describe how AI will develop interactive content\u2014such as real-time quizzes, customized practice problems, and detailed walkthroughs of circuit diagrams\u2014that align with students' progress and areas of improvement.</p> <p>Simulations and Animations: Outline how AI-powered simulations will allow students to interact with virtual circuit models, adjusting parameters and observing outcomes in real-time, and how animations will visually represent phenomena like current flow and voltage changes.</p> <p>Learning Activities and Projects: Explain how generative AI will generate scaffolded project suggestions based on Bloom\u2019s higher-order objectives, like creating their own circuit designs or troubleshooting complex systems. AI should provide formative feedback throughout each step to foster critical thinking.</p> <p>Assessment and Feedback: Describe how AI-driven assessments will go beyond traditional grading, providing personalized feedback loops that prompt self-reflection, track learning progress, and guide students through iterative problem-solving exercises.</p> <p>The course description should aim to inspire curiosity and convey how AI enhances interactivity and personalizes the learning journey, supporting students in achieving a deep and practical understanding of circuits and systems.</p> <p>Give the course description, apply the Bloom Taxonomy to rewrite the course description into a set of precise levels.</p> <p>Leverage Bloom\u2019s Taxonomy to structure the course, detailing the knowledge, skills, and applications students will develop at each cognitive level (remember, understand, apply, analyze, evaluate, and create).</p> <p>In the description, highlight how generative AI will serve as a primary teaching tool in the following ways:</p> <p>Metaphors and Analogies: Explain how generative AI will dynamically create metaphors that help students understand complex circuits and system concepts intuitively, for example, comparing [XXX] to [YYY] different contexts.</p> <p>Stories and Lessons: Illustrate how AI-generated narratives will guide students through historical milestones in circuit design, with characters like pioneering engineers or scientists to add context and enhance engagement.</p> <p>Content Generation: Describe how AI will develop interactive content\u2014such as real-time quizzes, customized practice problems, and detailed walkthroughs of circuit diagrams\u2014that align with students' progress and areas of improvement.</p> <p>Simulations and Animations: Outline how AI-powered simulations will allow students to interact with virtual circuit models, adjusting parameters and observing outcomes in real-time, and how animations will visually represent phenomena like current flow and voltage changes.</p> <p>Learning Activities and Projects: Explain how generative AI will generate scaffolded project suggestions based on Bloom\u2019s higher-order objectives, like creating their own circuit designs or troubleshooting complex systems. AI should provide formative feedback throughout each step to foster critical thinking.</p> <p>Assessment and Feedback: Describe how AI-driven assessments will go beyond traditional grading, providing personalized feedback loops that prompt self-reflection, track learning progress, and guide students through iterative problem-solving exercises.</p> <p>The course description should aim to inspire curiosity and convey how AI enhances interactivity and personalizes the learning journey, supporting students in achieving a deep and practical understanding of circuits and systems.</p>"},{"location":"prompts/02-bloom-taxonomy-description/#course-description","title":"Course Description","text":"<p>Organization: University of Minnesota Department of Electrical Engineering and Computer Design (EECD) Course Identifier: EE 4940 Course Title: : Introduction to Deep Learning Offering Date: Spring 2025</p>"},{"location":"prompts/02-bloom-taxonomy-description/#course-instructor","title":"Course Instructor","text":"<p>Sang-Hyun Oh, Professor of ECE, graduate faculty in neuroscience, physics, biomedical eng. Email: sang@umn.edu Office: 5-119 Keller Hall Teaching Assistant: Ike Goetzman (PhD candidate in ECE; email: goetz219@umn.edu) Lecture (Jan 22 \u2013 May 5, 2024): Monday/Wednesday 11:15am-12:30pm @ Appleby Hall 3</p>"},{"location":"prompts/02-bloom-taxonomy-description/#course-summary","title":"Course Summary","text":"<p>Machine learning, especially deep learning based on neural networks, has shown transformative impacts across life sciences, engineering, and medicine, as recently highlighted by the 2024 Nobel Prizes: </p> <ul> <li>The Physics Nobel was awarded to John Hopfield and Geoffrey Hinton for pioneering contributions to neural networks that enable machine learning</li> <li>Demis Hassabis, John Jumper, and David Baker received the Chemistry Nobel for advancing computational protein design.</li> </ul>"},{"location":"prompts/02-bloom-taxonomy-description/#course-overview","title":"Course Overview","text":"<p>EE 4940: Introduction to Deep Learning aims to provide students with both fundamental and applied perspectives on these advances. Beginning with an overview of AI, the course introduces deep neural networks (DNNs) through practical, hands-on examples and guides students through specialized neural network architectures, including</p> <ul> <li>convolutional neural networks (CNNs) for diagnostic applications and </li> <li>recurrent neural networks (RNNs) for time series analysis.</li> </ul> <p>Emphasis is placed on applying neural networks to tackle real-world problems in classification, regression, image analysis, and time-series prediction. Scientific applications are demonstrated as well, such as using DNNs to solve equations.</p> <p>The course concludes with dimensionality reduction techniques, followed by advanced topics such as generative AI, and an introduction to reinforcement learning. </p> <p>Emphasis will be on practical experience with Python-based coding over mathematical theory.</p> <p>By the end of the course, students will have gained familiarity with Python-driven deep learning, hands-on skills, and a working knowledge of deep learning\u2019s potential for a wide range of problems.</p>"},{"location":"prompts/02-bloom-taxonomy-description/#course-prerequisites","title":"Course Prerequisites","text":"<p>EE 4940 - Special Topics in Electrical and Computer Engineering is recommended but not required.</p> <p>This course is designed to be accessible and introductory, with essential concepts and coding skills introduced as needed.</p>"},{"location":"prompts/02-bloom-taxonomy-description/#expected-workload","title":"Expected Workload","text":"<p>This course (EE 4940) is a 3-credit, lecture format course. The expected workload for this course this semester is, on average, 45 hours per credit, or just over 3 hours per credit hour per week (including lecture). The total workload of 9 hours per week.</p>"},{"location":"prompts/02-bloom-taxonomy-description/#course-goals-and-objectives","title":"Course Goals and Objectives","text":"<p>EE 4940 aims to equip students with a foundation in deep learning, focusing on core architectures like deep neural networks (DNNs), convolutional neural networks (CNNs), and recurrent neural networks (RNNs).</p> <p>Through hands-on applications, students will learn to apply these models to solve practical problems using real-world datasets, such as cancer diagnostics and time-series analysis. The primary goal of the course is to develop students's ability to implement and troubleshoot neural network models, gaining some practical experiences, and be aware of potential pitfalls/artifacts while using DNNs.</p> <p>By the course's end, students will have a working knowledge of AI\u2019s role in scientific problem-solving, dimensionality reduction techniques, and a simple introduction to generative models and reinforcement learning (RL).</p>"},{"location":"prompts/02-bloom-taxonomy-description/#topics-to-be-covered","title":"Topics To Be Covered","text":""},{"location":"prompts/02-bloom-taxonomy-description/#1-introduction-to-ai-and-deep-learning","title":"1. Introduction to AI and deep learning","text":"<ul> <li>Brief history of AI, neural networks and recent Nobel-winning breakthroughs in physics and chemistry</li> <li>Course setup, tools, and brief introduction to Python for deep learning</li> <li>The universality theorem and the manifold hypothesis</li> </ul>"},{"location":"prompts/02-bloom-taxonomy-description/#2-fundamentals-of-deep-neural-networks-dnns","title":"2. Fundamentals of Deep Neural Networks (DNNs)","text":"<ul> <li>Architecture of DNNs: layers, activation functions, and backpropagation</li> <li>Training, validation, and testing sets;</li> <li>Loss functions, gradient descent, mini-batches</li> <li>Hands-on coding</li> </ul>"},{"location":"prompts/02-bloom-taxonomy-description/#3-convolutional-neural-networks-cnns-applications-in-diagnostic-imaging","title":"3. Convolutional Neural Networks (CNNs) - applications in diagnostic imaging","text":"<ul> <li>CNN architecture</li> <li>Applying CNNs, with MHIST as a case study for cancer diagnosis</li> </ul>"},{"location":"prompts/02-bloom-taxonomy-description/#4-recurrent-neural-networks-rnns-and-time-series-analysis","title":"4. Recurrent Neural Networks (RNNs) and time series analysis","text":"<ul> <li>Introduction to RNNs, LSTMs, for sequency data analysis.</li> <li>Hands-on practice with real-world data.</li> </ul>"},{"location":"prompts/02-bloom-taxonomy-description/#5-chips-and-ai","title":"5. Chips and AI","text":"<p>Briefly explore AI chips, neuromorphic devices, and future directions.</p>"},{"location":"prompts/02-bloom-taxonomy-description/#6-ai-for-scientific-problem-solving-using-neural-networks-to-approximate-solutions-for","title":"6. AI for scientific problem solving: Using neural networks to approximate solutions for","text":"<p>Maxwell\u2019s equations</p>"},{"location":"prompts/02-bloom-taxonomy-description/#7-dimensionality-reduction-and-autoencoders","title":"7. Dimensionality reduction and autoencoders","text":""},{"location":"prompts/02-bloom-taxonomy-description/#8-advanced-topics","title":"8. Advanced topics","text":""},{"location":"prompts/02-bloom-taxonomy-description/#course-format","title":"Course Format","text":"<ul> <li>Classroom lectures only</li> <li>Canvas LMS link will be provided</li> <li>Textbook and Required Materials: none</li> <li>Based on lecture notes (uploaded in canvas 1-2 days before class)</li> </ul>"},{"location":"prompts/02-bloom-taxonomy-description/#homework-assignments-and-mini-projects","title":"Homework Assignments and \u201cMini-projects\u201d:","text":"<ul> <li>Regularly-scheduled weekly or biweekly homework assignments and 4 multi-week \u201cmini-projects.\u201d The former will be designed to exercise basic concepts and modest extensions of the technical or computational tools introduced in class; the latter will be crafted to allow students to take a \u201cdeeper dive\u201d by applying techniques developed in the course to data sets arising in various aspects of ECE and life sciences.</li> <li>You are allowed (in fact, encouraged) to work with others when solving the homework and mini project problems. However, solutions submitted for grading should be formulated by each student independently! Late homework and mini-project submissions will be accepted, but without a legitimate (e.g., illness-based) justification, will result in a maximum grade of 80% for that assignment. Specifically, unjustified late assignments will be graded according to the same rubric as on-time assignments, but the corresponding score will be multiplied by 0.8 when entered into the gradebook.</li> </ul>"},{"location":"prompts/02-bloom-taxonomy-description/#exams","title":"Exams","text":"<p>There will be one midterm exam and one final exam. The midterm exam will be open book/notes. The final exam will be open book/notes and will be due no earlier than the final exam time specified by the Registrar. Either or both may be take-home exams.</p>"},{"location":"prompts/02-bloom-taxonomy-description/#grading","title":"Grading","text":"<p>The grade distributions for the course variations are provided below.</p> <p>Note: distributions for homework assignments and mini-projects are total; individual submissions will be equally weighted.</p> Deliverable Weight Homework Assignments 40% Mini-projects 40% Midterm Exam 10% Final Exam 10%"},{"location":"prompts/02-bloom-taxonomy-description/#software-requirements","title":"Software Requirements","text":"<p>Through the homework assignments and mini-projects, students will be required to perform a number of computer exercises to become familiar with the computational and practical aspects of deep learning. This will typically entail utilization of Python, often in concert with existing toolboxes such as NumPy, SciPy, Matplotlib, Scikit-learn, and PyTorch (or TensorFlow), all of which are freely available for Windows, Mac, and Linux operating systems.</p> <p>As a perhaps preferred alternative, students may wish to perform all (Python) programming computations using a free cloud-based account (i.e., Google Colab), which will be discussed and established at the beginning of the semester. Large-scale deep learning computations necessary for the final \u201cmini-project\u201d will utilize these resources.</p> <p>Note</p> <p>The Required University Policy Statements were provided in the original PDF of the course description.  They have been removed to allow the generative AI tools to focus on the concept enumeration.</p>"},{"location":"prompts/02-bloom-taxonomy-description/#result","title":"Result","text":"<p>Chat GPT o1 Thought about deep learning course structure for 42 seconds</p> <p>Below is a revised course description for EE 4940: Introduction to Deep Learning structured according to Bloom's Taxonomy. Each level highlights the knowledge, skills, and applications students will develop, as well as how generative AI will serve as a primary teaching tool---through metaphor/analogy generation, narrative stories, adaptive content creation, real-time simulations, scaffolded projects, and personalized assessment.</p>"},{"location":"prompts/02-bloom-taxonomy-description/#course-information","title":"Course Information","text":"<ul> <li>Organization: University of Minnesota Department of Electrical Engineering and Computer Design (EECD)</li> <li>Course Identifier: EE 4940</li> <li>Course Title: Introduction to Deep Learning</li> <li>Offering Date: Spring 2025</li> </ul>"},{"location":"prompts/02-bloom-taxonomy-description/#instructor-and-teaching-assistant","title":"Instructor and Teaching Assistant","text":"<ul> <li>Instructor:     Sang-Hyun Oh, Professor of ECE (graduate faculty in neuroscience, physics, biomedical engineering)     Email: sang@umn.edu     Office: 5-119 Keller Hall</li> <li>Teaching Assistant:     Ike Goetzman (PhD candidate in ECE)     Email: goetz219@umn.edu</li> <li>Lecture Schedule (Jan 22 -- May 5, 2024):     Monday/Wednesday 11:15am-12:30pm @ Appleby Hall 3</li> </ul>"},{"location":"prompts/02-bloom-taxonomy-description/#course-summary_1","title":"Course Summary","text":"<p>Machine learning---particularly deep learning---is transforming fields from life sciences to engineering and medicine. Inspired by recent Nobel Prize recognitions (e.g., John Hopfield and Geoffrey Hinton in Physics for neural network breakthroughs, Demis Hassabis, John Jumper, and David Baker in Chemistry for computational protein design), this course provides an introductory yet hands-on exploration of deep neural networks (DNNs), covering CNNs for image analysis, RNNs for time-series data, dimensionality reduction, an introduction to generative AI, and a glimpse of reinforcement learning.</p> <p>Students will gain practical coding experience in Python with toolkits such as PyTorch or TensorFlow, applying deep learning techniques to real-world datasets (e.g., cancer diagnostics, time-series forecasting).</p>"},{"location":"prompts/02-bloom-taxonomy-description/#prerequisites-format-and-workload","title":"Prerequisites, Format, and Workload","text":"<ul> <li>Prerequisites: EE 4940 - Special Topics in Electrical and Computer Engineering recommended but not required.</li> <li>Format: In-person lectures; no required textbook---lectures and notes via Canvas LMS.</li> <li>Workload: 3-credit lecture course (~9 hours/week total).<ul> <li>Weekly/biweekly homework.</li> <li>4 \"mini-projects\" involving deeper applications of course concepts.</li> <li>One midterm exam (open book/notes) and one final exam (open book/notes).</li> </ul> </li> </ul>"},{"location":"prompts/02-bloom-taxonomy-description/#course-goals-and-objectives_1","title":"Course Goals and Objectives","text":"<p>By the end of the course, students will:</p> <ul> <li>Have a working knowledge of deep neural network architectures (DNNs, CNNs, RNNs).</li> <li>Understand training, validation, and testing processes, gradient descent, backpropagation.</li> <li>Apply models to diagnostic imaging, time-series forecasting, and other real-world problems.</li> <li>Explore dimensionality reduction and see how DNNs can solve scientific problems (e.g., approximating solutions to Maxwell's equations).</li> <li>Gain a basic introduction to generative AI and reinforcement learning.</li> </ul>"},{"location":"prompts/02-bloom-taxonomy-description/#blooms-taxonomy-levels-and-the-role-of-generative-ai","title":"Bloom's Taxonomy Levels and the Role of Generative AI","text":"<p>Below is how this course---and its use of generative AI---aligns with each cognitive level of Bloom's Taxonomy: Remember, Understand, Apply, Analyze, Evaluate, and Create.</p>"},{"location":"prompts/02-bloom-taxonomy-description/#1-remember","title":"1. Remember","text":"<p>Knowledge &amp; Skills</p> <ul> <li>Recall fundamental definitions of artificial intelligence, neural networks, activation functions, backpropagation, and key historical milestones (e.g., Hopfield networks, Hinton's contributions).</li> <li>Identify standard Python libraries and deep learning frameworks (NumPy, SciPy, Matplotlib, PyTorch, TensorFlow).</li> </ul> <p>Generative AI in Action</p> <ul> <li>Metaphors and Analogies: The AI tool will generate simple, memorable analogies (e.g., \"A neural network layer is like a network of interconnected 'filters'---just like the lenses in glasses that each focus on a different part of the scene.\"). These real-time analogies help students quickly remember and anchor new terminology.</li> <li>Content Generation: AI-powered flashcards and micro-quizzes will be automatically created to help students memorize key terms, layer types, and function names.</li> </ul>"},{"location":"prompts/02-bloom-taxonomy-description/#2-understand","title":"2. Understand","text":"<p>Knowledge &amp; Skills</p> <ul> <li>Interpret how DNNs learn internal representations of data.</li> <li>Summarize the logic behind training/validation/test splits and how loss functions guide model optimization.</li> <li>Explain the significance of convolutional filters in CNNs and gating mechanisms in RNNs.</li> </ul> <p>Generative AI in Action</p> <ul> <li>Stories and Lessons: AI-generated narratives and role-play scenarios (e.g., \"Geoffrey Hinton explains to a young Demis Hassabis how hidden layers revolutionized speech recognition\") immerse students in historical contexts. These stories make key concepts in deep learning more relatable, fostering deeper understanding.</li> <li>Real-Time Clarifications: When students pose questions, AI can craft new explanations or analogies on the spot---ensuring that confusing topics are re-framed until fully understood.</li> </ul>"},{"location":"prompts/02-bloom-taxonomy-description/#3-apply","title":"3. Apply","text":"<p>Knowledge &amp; Skills</p> <ul> <li>Use Python and popular libraries to build, train, and test basic DNN architectures.</li> <li>Implement CNNs for image-based classification tasks and RNNs for time-series predictions.</li> <li>Employ data preprocessing techniques (normalization, reshaping) and iterative model refinement in mini-projects.</li> </ul> <p>Generative AI in Action</p> <ul> <li>Content Generation: Interactive practice problems and short coding challenges adapt to each student's progress. If a learner struggles with CNN kernel concepts, AI will generate targeted exercises.</li> <li>Simulations and Animations: Students use AI-driven virtual labs to manipulate hyperparameters and watch real-time changes in learning curves, explore \"zoomed-in\" views of convolutional filters, or tweak RNN cell parameters to see how model predictions shift---bridging theory and practice.</li> </ul>"},{"location":"prompts/02-bloom-taxonomy-description/#4-analyze","title":"4. Analyze","text":"<p>Knowledge &amp; Skills</p> <ul> <li>Compare different network architectures (DNN, CNN, RNN) for specific applications, examining performance metrics (accuracy, precision, recall, F1 scores).</li> <li>Investigate model failures or anomalies, diagnosing potential issues like overfitting or underfitting.</li> <li>Break down real-world datasets (e.g., MHIST for cancer diagnosis) to identify patterns and design suitable learning strategies.</li> </ul> <p>Generative AI in Action</p> <ul> <li>Learning Activities and Projects: AI proposes incremental \"mini-projects\" that require critical data analysis---such as comparing performance across multiple model architectures or investigating feature maps in CNNs. The AI offers real-time hints, ensuring students learn systematic analysis methods.</li> <li>Adaptive Feedback: As students debug their models, AI-powered suggestions highlight where and why training might be failing, prompting reflection on data splits, loss function choices, or architectural mismatches.</li> </ul>"},{"location":"prompts/02-bloom-taxonomy-description/#5-evaluate","title":"5. Evaluate","text":"<p>Knowledge &amp; Skills</p> <ul> <li>Assess the reliability, interpretability, and ethical considerations of deep learning solutions.</li> <li>Critique model architecture decisions, optimization techniques, and the trade-offs between computational cost and accuracy.</li> <li>Determine when alternative approaches (e.g., simpler regressions or decision trees) might be more suitable than deep networks.</li> </ul> <p>Generative AI in Action</p> <ul> <li>Assessment and Feedback: AI-driven grading provides personalized feedback loops that go beyond numeric scores. Students receive suggestions (e.g., \"Try re-evaluating your dropout strategy. Are you balancing variance and bias properly?\"), enabling them to evaluate and refine their approach.</li> <li>Peer Review Simulations: Generative AI simulates a peer-review environment, providing constructive critiques of project proposals or final results---students practice giving and receiving evaluations in a supportive, simulated setting.</li> </ul>"},{"location":"prompts/02-bloom-taxonomy-description/#6-create","title":"6. Create","text":"<p>Knowledge &amp; Skills</p> <ul> <li>Design and implement original neural network architectures for novel data domains.</li> <li>Experiment with generative models (e.g., Variational Autoencoders or Generative Adversarial Networks) and propose new applications for them.</li> <li>Formulate and conduct reinforcement learning experiments for simple control or decision-making problems.</li> </ul> <p>Generative AI in Action</p> <ul> <li>Learning Activities and Projects: The AI tool auto-generates scaffolded project suggestions that encourage students to develop new solutions---\"Propose a CNN variant for biomedical image segmentation,\" or \"Design an RNN-based text predictor with user-defined constraints.\"</li> <li>Formative Feedback: Throughout the creative process, the AI continually checks code, results, and design decisions, prompting deeper critical thinking. This fosters an iterative cycle of hypothesis-testing and refinement---helping students truly create and innovate.</li> </ul>"},{"location":"prompts/02-bloom-taxonomy-description/#how-generative-ai-personalizes-the-learning-journey","title":"How Generative AI Personalizes the Learning Journey","text":"<ol> <li> <p>Metaphors and Analogies</p> <ul> <li>Ongoing generation of simple and relatable comparisons for abstract concepts, ensuring students never get stuck on jargon.</li> <li> <p>Stories and Lessons</p> </li> <li> <p>AI-developed narratives infuse historical milestones (Hopfield nets, Hinton's backpropagation breakthroughs, Hassabis's achievements) with character-driven storytelling.</p> </li> <li> <p>Content Generation</p> </li> <li> <p>Adaptive quizzes, customized practice problems, and circuit-like diagram walk-throughs (adapted to deep learning diagrams) grow alongside the student's evolving competence.</p> </li> <li> <p>Simulations and Animations</p> </li> <li> <p>AI-powered interfaces let students see real-time \"inside\" changes as a model learns---activations, gradients, confusion matrices---supporting interactive exploration.</p> </li> <li> <p>Learning Activities and Projects</p> </li> <li> <p>Scaffolded tasks guide novices from basic classification examples to more advanced challenges---like building an autoencoder for dimensionality reduction or a basic reinforcement learning agent.</p> </li> <li> <p>Assessment and Feedback</p> </li> <li> <p>Detailed, iterative feedback loops ensure students understand why a concept or code block fails, equipping them to self-reflect, iterate, and improve.</p> </li> </ul> </li> </ol>"},{"location":"prompts/02-bloom-taxonomy-description/#grading-overview","title":"Grading Overview","text":"Deliverable Weight Homework Assignments 40% --- --- Mini-projects 40% Midterm Exam 10% Final Exam 10% <p>Note: Late submissions (without legitimate justification) receive up to 80% credit. Exams are open-book/notes and may include take-home components.</p>"},{"location":"prompts/02-bloom-taxonomy-description/#conclusion","title":"Conclusion","text":"<p>By integrating Bloom's Taxonomy with generative AI-powered tools, EE 4940: Introduction to Deep Learning aspires to spark curiosity and deep engagement. Students will remember core principles, understand architectural choices, apply techniques to real data, analyze model results, evaluate ethical and practical considerations, and ultimately create new solutions in the rapidly evolving field of deep learning. This comprehensive and interactive approach---fueled by dynamic AI metaphors, narratives, simulations, and personalized feedback---ensures that each learner can explore and master the foundational and forward-looking aspects of modern neural network technology.</p> <p>o1</p> <p>O</p>"},{"location":"prompts/03-concept-enumeration/","title":"Concept Enumeration","text":"<p>Prompt</p> <p>Please generate a list of the 200 core concepts that need to be covered in this course and the order in which they should be taught.</p> <p>Return numbered list of these core concepts using a single line per concept.  For each concept, just return a short concept name and use acronyms or abbreviations when appropriate.  They will be used as labels in a graph network. Make sure that the concepts are distinct not duplicated in the list.</p> <p>Use title case for the concept names.</p> <p>Start with the most basic foundational concepts and then proceed to the most complex concepts.</p>"},{"location":"prompts/03-concept-enumeration/#workflow","title":"Workflow","text":"<p>Setting the stage</p> <p>I'm compiling a list of 200 unique core concepts for a deep learning course. The order will start with basic concepts and gradually advance to more complex ones.</p> <p>Expanding the list</p> <p>I'm building upon the course outline to include topics like generative AI and RL, ensuring each is distinct and enumerated correctly while avoiding duplicates.</p> <p>Organizing topics</p> <p>Structuring the course into categories like basic foundations, Python tools, and advanced topics such as generative AI and domain-specific architectures to ensure a systematic progression.</p> <p>Finalizing concepts</p> <p>Wrapping up the course with distinctions like \"AI Definition\" and \"ML Definition,\" ensuring clarity with concise, title-case concepts in 200 carefully enumerated lines.</p> <p>Ensuring clarity</p> <p>I'm refining concepts like \"AI Definition\" and \"ML Definition,\" combining title case and potentially using acronyms for distinct clarity. The goal is to maintain precision and avoid redundancy.</p> <p>Detailed line distribution</p> <p>I'm assigning 10-line chunks to various topics, such as Python, ML fundamentals, neural networks, and advanced architectures, ensuring comprehensive coverage across all 200 lines.</p> <p>Progressing through topics</p> <p>I'm charting our course with concise lines to cover \"NN Fundamentals\" and \"Training Processes,\" ensuring distinct and systematic progression across 200 meticulously controlled entries.</p> <p>Venturing into complexity</p> <p>I'm exploring advanced topics in neural networks, including special architectures like Capsule Networks and Tree-Augmented Naive Bayes, as well as Transformer techniques for natural language processing.</p> <p>Unraveling generative AI</p> <p>I'm analyzing advanced generative models and reinforcement learning techniques. This involves delving into diffusion models, denoising diffusion, principal components, and ethical considerations like fairness and privacy.</p> <p>Mapping deployment and application</p> <p>I'm covering GPU and TPU acceleration, memory management, model compression, and practical applications like computer vision and autonomous driving. This completes the cycle, ensuring comprehensive coverage.</p>"},{"location":"prompts/03-concept-enumeration/#result","title":"Result","text":"<p>Thought about deep learning curriculum concepts for 1m 42s AI Definition ML Definition History Of AI Nobel Prizes Key Figures AI Branches Symbolic AI Data-Driven AI NN Origins Biological Inspiration Python Setup Conda Environment Jupyter Notebooks NumPy Basics Pandas Basics Matplotlib Basics SciPy Basics Scikit-Learn Overview PyTorch Intro TensorFlow Intro Supervised Vs Unsupervised Regression Vs Classification Overfitting Vs Underfitting Training-Validation-Test Bias-Variance Tradeoff Regularization Overview Cross-Validation Evaluation Metrics Loss Functions Gradient Descent Data Preprocessing Scaling And Normalization Data Augmentation Feature Engineering Dimensionality Concepts Data Splits Data Visualization Data Cleaning Data Imbalance Data Ethics Perceptron Model Multi-Layer Perceptron Activation Functions Forward Propagation Backpropagation Weights And Biases Batch Training Mini-Batch Training Stochastic Training Learning Rate Loss Surface Local Minima Vanishing Gradients Exploding Gradients Initialization Methods He Initialization Xavier Initialization Momentum Optimizer AdaGrad Adam Optimizer Convolution Operation Filters And Kernels Pooling Layers Stride And Padding Fully Connected Layers Batch Normalization CNN Architectures ImageNet Transfer Learning Basics Object Detection Sequence Modeling Vanilla RNN LSTM Units GRU Units Backprop Through Time (BPTT) Exploding Gradient Control Language Modeling Text Generation Time-Series Forecasting Attention Mechanism Deep Architecture Layer Stacking Depth Vs Width Residual Networks (ResNet) Inception Modules DenseNet Skip Connections Dropout BatchNorm Weight Decay Capsule Networks Graph Neural Networks (GNNs) Transformers Intro Vision Transformers (ViT) Self-Attention Positional Encoding BERT Overview GPT Overview Sequence-To-Sequence Neural Machine Translation Generative Models Autoencoders (AE) Variational Autoencoders (VAE) GAN Basics Generator Vs Discriminator Latent Space Conditional GAN CycleGAN Style Transfer Text-To-Image Diffusion Models Denoising Diffusion Score Matching Likelihood Estimation Energy-Based Models Flow-Based Models Prompt Engineering Text Generation Models Large Language Models (LLMs) ChatGPT Concept PCA t-SNE UMAP Autoencoder DR Manifold Hypothesis Feature Space Principal Components Nonlinear Embeddings High-Dimensional Data Data Visualization Tools RL Definition Markov Decision Process (MDP) Value Functions Policy Gradient Q-Learning Deep Q-Network (DQN) Actor-Critic Reward Shaping Exploration Vs Exploitation Baseline Algorithms Model Interpretability Explainable AI (XAI) SHAP LIME Fairness Bias Mitigation Privacy Security Adversarial Examples Responsible AI GPU Acceleration TPU Acceleration Memory Management Model Compression Quantization Pruning Edge Deployment Cloud Services AutoML MLOps Hyperparameter Tuning Grid Search Random Search Bayesian Optimization Early Stopping Learning Rate Scheduling Data Parallelism Model Parallelism Checkpointing Version Control Accuracy Precision Recall F1 Score AUC-ROC Confusion Matrix Top-1 Vs Top-5 Accuracy BLEU Score Perplexity Mean Squared Error (MSE) Computer Vision Natural Language Processing (NLP) Speech Recognition Medical Imaging Drug Discovery Protein Folding Autonomous Driving Robotics Financial Forecasting Recommender Systems Project Scoping Requirement Analysis Data Acquisition Data Annotation Resource Allocation Team Collaboration Version Control Workflow Agile Methods Code Review Documentation</p>"},{"location":"prompts/03-concept-enumeration/#getting-the-csv","title":"Getting the CSV","text":"<p>Prompt</p> <p>please return this list in a single csv file with the first column as ConceptID and the second column as ConceptLabel</p> <pre><code>import pandas as pd\n\n# Define the list of concepts\nconcepts = [\n    \"AI Definition\", \"ML Definition\", \"History Of AI\", \"Nobel Prizes\", \"Key Figures\", \"AI Branches\", \"Symbolic AI\",\n    \"Data-Driven AI\", \"NN Origins\", \"Biological Inspiration\", \"Python Setup\", \"Conda Environment\", \"Jupyter Notebooks\",\n    \"NumPy Basics\", \"Pandas Basics\", \"Matplotlib Basics\", \"SciPy Basics\", \"Scikit-Learn Overview\", \"PyTorch Intro\",\n    \"TensorFlow Intro\", \"Supervised Vs Unsupervised\", \"Regression Vs Classification\", \"Overfitting Vs Underfitting\",\n    \"Training-Validation-Test\", \"Bias-Variance Tradeoff\", \"Regularization Overview\", \"Cross-Validation\",\n    \"Evaluation Metrics\", \"Loss Functions\", \"Gradient Descent\", \"Data Preprocessing\", \"Scaling And Normalization\",\n    \"Data Augmentation\", \"Feature Engineering\", \"Dimensionality Concepts\", \"Data Splits\", \"Data Visualization\",\n    \"Data Cleaning\", \"Data Imbalance\", \"Data Ethics\", \"Perceptron Model\", \"Multi-Layer Perceptron\",\n    \"Activation Functions\", \"Forward Propagation\", \"Backpropagation\", \"Weights And Biases\", \"Batch Training\",\n    \"Mini-Batch Training\", \"Stochastic Training\", \"Learning Rate\", \"Loss Surface\", \"Local Minima\",\n    \"Vanishing Gradients\", \"Exploding Gradients\", \"Initialization Methods\", \"He Initialization\",\n    \"Xavier Initialization\", \"Momentum Optimizer\", \"AdaGrad\", \"Adam Optimizer\", \"Convolution Operation\",\n    \"Filters And Kernels\", \"Pooling Layers\", \"Stride And Padding\", \"Fully Connected Layers\", \"Batch Normalization\",\n    \"CNN Architectures\", \"ImageNet\", \"Transfer Learning Basics\", \"Object Detection\", \"Sequence Modeling\",\n    \"Vanilla RNN\", \"LSTM Units\", \"GRU Units\", \"Backprop Through Time (BPTT)\", \"Exploding Gradient Control\",\n    \"Language Modeling\", \"Text Generation\", \"Time-Series Forecasting\", \"Attention Mechanism\", \"Deep Architecture\",\n    \"Layer Stacking\", \"Depth Vs Width\", \"Residual Networks (ResNet)\", \"Inception Modules\", \"DenseNet\",\n    \"Skip Connections\", \"Dropout\", \"BatchNorm\", \"Weight Decay\", \"Capsule Networks\", \"Graph Neural Networks (GNNs)\",\n    \"Transformers Intro\", \"Vision Transformers (ViT)\", \"Self-Attention\", \"Positional Encoding\", \"BERT Overview\",\n    \"GPT Overview\", \"Sequence-To-Sequence\", \"Neural Machine Translation\", \"Generative Models\", \"Autoencoders (AE)\",\n    \"Variational Autoencoders (VAE)\", \"GAN Basics\", \"Generator Vs Discriminator\", \"Latent Space\", \"Conditional GAN\",\n    \"CycleGAN\", \"Style Transfer\", \"Text-To-Image\", \"Diffusion Models\", \"Denoising Diffusion\", \"Score Matching\",\n    \"Likelihood Estimation\", \"Energy-Based Models\", \"Flow-Based Models\", \"Prompt Engineering\", \"Text Generation Models\",\n    \"Large Language Models (LLMs)\", \"ChatGPT Concept\", \"PCA\", \"t-SNE\", \"UMAP\", \"Autoencoder DR\", \"Manifold Hypothesis\",\n    \"Feature Space\", \"Principal Components\", \"Nonlinear Embeddings\", \"High-Dimensional Data\", \"Data Visualization Tools\",\n    \"RL Definition\", \"Markov Decision Process (MDP)\", \"Value Functions\", \"Policy Gradient\", \"Q-Learning\",\n    \"Deep Q-Network (DQN)\", \"Actor-Critic\", \"Reward Shaping\", \"Exploration Vs Exploitation\", \"Baseline Algorithms\",\n    \"Model Interpretability\", \"Explainable AI (XAI)\", \"SHAP\", \"LIME\", \"Fairness\", \"Bias Mitigation\", \"Privacy\",\n    \"Security\", \"Adversarial Examples\", \"Responsible AI\", \"GPU Acceleration\", \"TPU Acceleration\", \"Memory Management\",\n    \"Model Compression\", \"Quantization\", \"Pruning\", \"Edge Deployment\", \"Cloud Services\", \"AutoML\", \"MLOps\",\n    \"Hyperparameter Tuning\", \"Grid Search\", \"Random Search\", \"Bayesian Optimization\", \"Early Stopping\",\n    \"Learning Rate Scheduling\", \"Data Parallelism\", \"Model Parallelism\", \"Checkpointing\", \"Version Control\",\n    \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"AUC-ROC\", \"Confusion Matrix\", \"Top-1 Vs Top-5 Accuracy\",\n    \"BLEU Score\", \"Perplexity\", \"Mean Squared Error (MSE)\", \"Computer Vision\", \"Natural Language Processing (NLP)\",\n    \"Speech Recognition\", \"Medical Imaging\", \"Drug Discovery\", \"Protein Folding\", \"Autonomous Driving\", \"Robotics\",\n    \"Financial Forecasting\", \"Recommender Systems\", \"Project Scoping\", \"Requirement Analysis\", \"Data Acquisition\",\n    \"Data Annotation\", \"Resource Allocation\", \"Team Collaboration\", \"Version Control Workflow\", \"Agile Methods\",\n    \"Code Review\", \"Documentation\"\n]\n\n# Create a DataFrame with ConceptID and ConceptLabel\ndf = pd.DataFrame({\n    \"ConceptID\": range(1, len(concepts) + 1),\n    \"ConceptLabel\": concepts\n})\n\n# Save the DataFrame to a CSV file\nfile_path = \"/mnt/data/EE4940_Core_Concepts.csv\"\ndf.to_csv(file_path, index=False)\n\nfile_path\n</code></pre>"},{"location":"prompts/03-concept-enumeration/#result_1","title":"Result","text":"<p>Deep Learning Concepts</p>"},{"location":"prompts/04-concept-dependencies/","title":"Concept Dependencies","text":"<p>Prompt</p> <p>Below is a CSV file of concepts in a course on Deep Learning for junior or senior college students.  Please use this CSV file of 200 concepts for the next step.</p> <p>Next, please create a fully connected concept dependency graph for the concepts in this course. In this step, for each Concept in the CSV file, create a new list of other concepts on which it depends.  If a concept depends on a specific concept that is not listed, then we will need to add it as a new concept. This will help us determine the teaching order of the Concepts.</p> <p>Return the new list as a CSV file using the following format:</p> <ol> <li>The first column in the CSV file is a ConceptID you assigned in the list above.</li> <li>The second column is the ConceptLabel</li> <li>The third column is called Dependencies.  It's format is a pipe-delimited list of the Concept IDs that the concept depends upon.</li> </ol> <p>Check your results to make sure that all concepts are connected to at least one other concept.</p> <p>Foundation Concepts are concepts that have no dependant concepts in this set.  They have an empty third column of Dependencies.</p> <p>In this example, the following concepts have no dependencies (empty Dependencies column). They serve as possible \u201cstarting points\u201d in the curriculum:</p> <ul> <li>1: AI Definition</li> <li>3: History Of AI</li> <li>10: Biological Inspiration</li> <li>11: Python Setup</li> <li>191: Project Scoping</li> </ul> <p>All other concepts depend on at least one earlier concept\u2014ensuring every concept is connected in one unified graph. Feel free to modify or expand these dependencies to match your exact course structure.</p>"},{"location":"prompts/04-concept-dependencies/#response","title":"Response","text":"<p>Foundation Concepts</p>"},{"location":"prompts/05-concept-taxonomy/","title":"Concept Taxonomy","text":"<p>Prompt</p> <p>Given the list of concepts, your next task is to organize these concepts into a taxonomy by grouping them into appropriate categories. Each category should include concepts that share similar characteristics, functions, or applications.</p> <p>Suggest 10-12 categories for the taxonomy and assign each concept to one or more categories. Ensure that the categories cover a range of concept types, including abstract ideas, practical applications, Python libraries, common misunderstandings, and real-world examples.</p> <p>Avoid redundancy and ensure that each category is distinct.</p> <p>Your first category is \"Foundational Concepts\", your second is \"Terms and Definitions\".   A final category might be \"Goals\".</p>"},{"location":"prompts/05-concept-taxonomy/#workflow","title":"Workflow","text":"<p>ChatGPT o1 thought about course taxonomy and categories for 3m 36s</p> <p>Crafting a taxonomy</p> <p>I'm organizing 200 concepts into 10-12 categories, including foundational concepts, terms and definitions, and goals. Ensuring a variety of concept types without redundancy.</p> <p>Shaping the categories</p> <p>I'm organizing the taxonomy with 10-12 categories, focusing on topics like foundational concepts, key tools, data engineering, core ML, model architectures, optimization, advanced topics, and real-world examples.</p> <p>Clarifying \"Goals\"</p> <p>Hmm, I'm thinking about whether \"Goals\" means measuring success, project scoping, or responsible AI like interpretability. Each concept will fit into one of the 10 categories.</p> <p>Shaping the framework</p> <p>I'm honing in on Python tools, data engineering, Neural Network Architectures, Reinforcement Learning, and integration with interpretation, ethics, fairness, MLOps, and project workflow.</p> <p>Mapping the categories</p> <p>I'm working through merging \"Interpretation, Ethics, &amp; Fairness\" with \"Goals,\" but it seems intricate and possibly ineffective. It's interesting to see these elements might be better handled separately.</p> <p>Refining the taxonomy</p> <p>I'm merging \"Sequence &amp; Natural Language\" with \"Advanced &amp; Specialized Topics,\" and integrating \"Reinforcement Learning\" into the revised category. This results in a sleeker, more coherent framework.</p> <p>Finalizing the categories</p> <p>I'm looking at a streamlined taxonomy with 11 categories, including Foundational Concepts, Python Tools, Data Engineering, Advanced Topics, and Real-World Applications. Assigning concepts to these categories now.</p> <p>Voucher assignment</p> <p>Deciding whether to include \"Nobel Prizes\" in \"Foundational Concepts\" or \"History of AI\" is tricky. I'll weigh the typical context for each category to make a balanced decision.</p> <p>Piecing together the foundation</p> <p>I'm carefully grouping concepts like AI and ML definitions, AI history, Nobel Prizes, key figures, AI branches, and neural networks into foundational concepts.</p> <p>Mapping out key concepts</p> <p>I'm digging into foundational concepts like AI and ML definitions, AI history, Nobel Prizes, key figures, AI branches, and neural network origins, ensuring a balanced and comprehensive approach.</p> <p>Clarifying definitions</p> <p>I'm thinking through terms for \"Terms and Definitions,\" focusing on clear, concise definitions like Supervised vs. Unsupervised learning, Regression vs. Classification, and evaluation metrics.</p> <p>Mapping concepts</p> <p>Pulling together Python tools, data engineering, neural network architectures, and advanced topics like transformers and generative models. Assigning terms systematically to refine clarity and avoid redundancy.</p> <p>Refining category alignment</p> <p>Consider placing \"Attention Mechanism\" under \"Neural Network Architectures.\" \"Reinforcement Learning\" and \"Advanced Recognition Techniques\" seem to fit well inside \"Advanced &amp; Specialized Topics.\"</p> <p>Merging concepts</p> <p>I'm contemplating combining \"Reinforcement Learning\" with \"Advanced &amp; Specialized Topics,\" and \"Project Scoping\" seems to fit better in \"MLOps &amp; Project Workflow\" or as \"Goals.\"</p> <p>Mapping real applications</p> <p>I'm organizing concepts on ethical AI, MLOps, and project workflow, including resource allocation, version control, and agile methods. Next up: integrating \"Project Scoping\" and refining \"Goals.\"</p> <p>Clarifying project metrics</p> <p>I'm thinking about including \"Evaluation Metrics\" and \"Project Scoping\" under \"Goals,\" refining their roles to ensure they align cohesively within the broader context.</p> <p>Integrating distinct elements</p> <p>I'm honing the \"Goals\" category with evaluation metrics, precision, recall, and other metrics. For dimensionality reduction and data visualization tools, they seem to fit better in \"Data Preparation &amp; Engineering\" or \"Training &amp; Optimization.\"</p> <p>Mapping concepts</p> <p>I'm integrating dimensionality reduction and data visualization tools into \"Data Preparation &amp; Engineering,\" and placing \"Prompt Engineering\" in \"Advanced &amp; Specialized Topics\" or \"Sequence &amp; Natural Language.\"</p> <p>Mapping as I go</p> <p>Integrating concepts like \"Prompt Engineering\" into \"Advanced &amp; Specialized Topics\" and aligning \"Attention Mechanism\" with \"Neural Network Architectures.\" Also, I'm finalizing the assignment of various ML and data concepts.</p> <p>Mapping out assignments</p> <p>There's a clear progression: integrating \"Data Ethics\" into \"Interpretation, Ethics, &amp; Fairness,\" placing \"ImageNet\" in \"Neural Network Architectures,\" and categorizing \"Text Generation\" with \"Advanced &amp; Specialized Topics.\"</p> <p>Organizing concepts</p> <p>I'm grouping \"Language Modeling\" and \"Text Generation\" into \"Advanced &amp; Specialized Topics,\" and aligning \"Attention Mechanism\" with \"Neural Network Architectures\". Robotics fits best in \"Real-World Applications.\"</p> <p>Organizing and refining</p> <p>Assigning concepts like \"Loss Surface\" and \"Data Annotation\" to \"Training &amp; Optimization\" and \"Data Prep &amp; MLOps\" respectively. \"Robotics\" fits well in \"Real-World Applications.\"</p> <p>Finalizing concepts</p> <p>I'm wrapping up by mapping \"ChatGPT Concept\" and \"Adversarial Examples\" to \"Advanced &amp; Specialized Topics\" and \"Interpretation, Ethics, &amp; Fairness,\" ensuring each concept is logically categorized.</p> <p>Finalizing mappings</p> <p>Assigning concepts like \"Quantization,\" \"Pruning,\" and \"Edge Deployment\" to \"Advanced &amp; Specialized Topics,\" and ensuring all concepts fit logically within the intended categories.</p> <p>Finalizing concepts</p> <p>I'm completing the mapping of advanced concepts like \"DQN,\" \"Actor-Critic,\" and \"Reward Shaping\" to \"Advanced &amp; Specialized Topics,\" and ensuring all terms are logically categorized.</p> <p>Piecing together assignments</p> <p>I'm ensuring \"SciPy\" fits into \"Python Tools,\" aligning \"Precision,\" \"Recall,\" \"F1,\" and \"AUC-ROC\" with \"Goals,\" and placing \"Data Splits\" and \"Data Visualization Tools\" under \"Data Prep &amp; Engineering.\"</p> <p>Aligning the framework</p> <p>Aligning \"GPU Acceleration\" and \"TPU Acceleration\" with \"Advanced &amp; Specialized Topics,\" \"Project Scoping\" and \"Version Control Workflow\" with \"MLOps &amp; Project Workflow.\"</p> <p>Refining concept categories</p> <p>I'm evolving \"Adam Optimizer\" and \"Hyperparameter Tuning\" within \"Training &amp; Optimization.\" \"Data Visualization\" and \"PCA\" fit snugly under \"Data Prep &amp; Engineering.\"</p> <p>Finalizing taxonomy</p> <p>OK, let me see. I'm ensuring each concept lands in the right category, refining concepts like \"Weight Decay\" and \"Evaluation Metrics.\" I'm setting a clear, concise list of 11 categories.</p> <p>Mapping out preferences</p> <p>I'm factoring in the need for brevity and the user's desire for a range of concept types. Considering a summarized 11-category list with multi-category assignments, focusing on practical applications and Python libraries.</p>"},{"location":"prompts/05-concept-taxonomy/#result","title":"Result","text":"<p>Below is an example taxonomy of the 200 concepts, grouped into 11 distinct categories. Each concept may appear in more than one category if it makes sense pedagogically (e.g., a concept can be both a \"term/definition\" and also relevant to \"training &amp; optimization\").</p> <p>In practice, you might refine these groupings further or redistribute concepts according to your specific course design. The primary goals are (1) to ensure that each concept is accounted for at least once, (2) to keep categories mutually distinct, and (3) to cover a wide range of types (abstract ideas, practical tools, potential pitfalls, real-world use cases, etc.).</p>"},{"location":"prompts/05-concept-taxonomy/#1-foundational-concepts","title":"1. Foundational Concepts","text":"<p>These are broad, high-level ideas or historical touchpoints on which other topics build.</p> <ul> <li>(1) AI Definition</li> <li>(2) ML Definition</li> <li>(3) History Of AI</li> <li>(4) Nobel Prizes</li> <li>(5) Key Figures</li> <li>(6) AI Branches</li> <li>(7) Symbolic AI</li> <li>(8) Data-Driven AI</li> <li>(9) NN Origins</li> <li>(10) Biological Inspiration</li> </ul>"},{"location":"prompts/05-concept-taxonomy/#2-terms-and-definitions","title":"2. Terms and Definitions","text":"<p>Key terminology and conceptual distinctions often introduced early to clarify the field's language.</p> <ul> <li>(21) Supervised Vs Unsupervised</li> <li>(22) Regression Vs Classification</li> <li>(23) Overfitting Vs Underfitting</li> <li>(25) Bias-Variance Tradeoff</li> <li>(35) Dimensionality Concepts</li> <li>(39) Data Imbalance</li> <li>(51) Loss Surface</li> <li>(52) Local Minima</li> <li>(62) Filters And Kernels</li> <li>(100) Neural Machine Translation</li> <li>(118) Text Generation Models</li> <li>(131) RL Definition</li> <li>(139) Exploration Vs Exploitation</li> </ul> <p>(Note that some of these also appear under other categories if they are central to training, optimization, or advanced topics.)</p>"},{"location":"prompts/05-concept-taxonomy/#3-python-tools-libraries","title":"3. Python Tools &amp; Libraries","text":"<p>Practical software tools used throughout the course for coding, data manipulation, and experimentation.</p> <ul> <li>(11) Python Setup</li> <li>(12) Conda Environment</li> <li>(13) Jupyter Notebooks</li> <li>(14) NumPy Basics</li> <li>(15) Pandas Basics</li> <li>(16) Matplotlib Basics</li> <li>(17) SciPy Basics</li> <li>(18) Scikit-Learn Overview</li> <li>(19) PyTorch Intro</li> <li>(20) TensorFlow Intro</li> </ul>"},{"location":"prompts/05-concept-taxonomy/#4-data-preparation-engineering","title":"4. Data Preparation &amp; Engineering","text":"<p>Concepts and techniques for acquiring, cleaning, organizing, and transforming data before (and during) model development.</p> <ul> <li>(31) Data Preprocessing</li> <li>(32) Scaling And Normalization</li> <li>(33) Data Augmentation</li> <li>(34) Feature Engineering</li> <li>(36) Data Splits</li> <li>(37) Data Visualization</li> <li>(38) Data Cleaning</li> <li>(40) Data Ethics (also appears in Ethics/Ethical Use)</li> <li>(121) PCA</li> <li>(122) t-SNE</li> <li>(123) UMAP</li> <li>(124) Autoencoder DR</li> <li>(125) Manifold Hypothesis</li> <li>(126) Feature Space</li> <li>(127) Principal Components</li> <li>(128) Nonlinear Embeddings</li> <li>(129) High-Dimensional Data</li> <li>(130) Data Visualization Tools</li> <li>(193) Data Acquisition</li> <li>(194) Data Annotation</li> </ul>"},{"location":"prompts/05-concept-taxonomy/#5-training-optimization","title":"5. Training &amp; Optimization","text":"<p>How models learn, common pitfalls, and methods to optimize performance.</p> <ul> <li>(23) Overfitting Vs Underfitting</li> <li>(24) Training-Validation-Test</li> <li>(25) Bias-Variance Tradeoff</li> <li>(26) Regularization Overview</li> <li>(27) Cross-Validation</li> <li>(29) Loss Functions</li> <li>(30) Gradient Descent</li> <li>(43) Activation Functions</li> <li>(44) Forward Propagation</li> <li>(45) Backpropagation</li> <li>(46) Weights And Biases</li> <li>(47) Batch Training</li> <li>(48) Mini-Batch Training</li> <li>(49) Stochastic Training</li> <li>(50) Learning Rate</li> <li>(52) Local Minima</li> <li>(53) Vanishing Gradients</li> <li>(54) Exploding Gradients</li> <li>(58) Momentum Optimizer</li> <li>(59) AdaGrad</li> <li>(60) Adam Optimizer</li> <li>(76) Exploding Gradient Control</li> <li>(90) Weight Decay</li> <li>(161) Hyperparameter Tuning</li> <li>(162) Grid Search</li> <li>(163) Random Search</li> <li>(164) Bayesian Optimization</li> <li>(165) Early Stopping</li> <li>(166) Learning Rate Scheduling</li> </ul>"},{"location":"prompts/05-concept-taxonomy/#6-neural-network-architectures","title":"6. Neural Network Architectures","text":"<p>Core structures and design choices in building various types of deep neural networks.</p> <ul> <li>(41) Perceptron Model</li> <li>(42) Multi-Layer Perceptron</li> <li>(55) Initialization Methods</li> <li>(56) He Initialization</li> <li>(57) Xavier Initialization</li> <li>(61) Convolution Operation</li> <li>(63) Pooling Layers</li> <li>(64) Stride And Padding</li> <li>(65) Fully Connected Layers</li> <li>(66) Batch Normalization</li> <li>(67) CNN Architectures</li> <li>(68) ImageNet</li> <li>(69) Transfer Learning Basics</li> <li>(70) Object Detection (also a real-world CV application)</li> <li>(71) Sequence Modeling</li> <li>(72) Vanilla RNN</li> <li>(73) LSTM Units</li> <li>(74) GRU Units</li> <li>(75) Backprop Through Time (BPTT)</li> <li>(79) Time-Series Forecasting</li> <li>(80) Attention Mechanism</li> <li>(81) Deep Architecture</li> <li>(82) Layer Stacking</li> <li>(83) Depth Vs Width</li> <li>(84) Residual Networks (ResNet)</li> <li>(85) Inception Modules</li> <li>(86) DenseNet</li> <li>(87) Skip Connections</li> <li>(88) Dropout</li> <li>(89) BatchNorm (duplicate of 66's concept family)</li> <li>(91) Capsule Networks</li> <li>(92) Graph Neural Networks (GNNs)</li> <li>(93) Transformers Intro</li> <li>(94) Vision Transformers (ViT)</li> <li>(95) Self-Attention</li> <li>(96) Positional Encoding</li> <li>(97) BERT Overview</li> <li>(98) GPT Overview</li> <li>(99) Sequence-To-Sequence</li> <li>(101) Generative Models</li> <li>(102) Autoencoders (AE)</li> <li>(103) Variational Autoencoders (VAE)</li> <li>(104) GAN Basics</li> <li>(105) Generator Vs Discriminator</li> <li>(106) Latent Space</li> <li>(107) Conditional GAN</li> <li>(108) CycleGAN</li> <li>(109) Style Transfer</li> <li>(110) Text-To-Image</li> <li>(111) Diffusion Models</li> <li>(112) Denoising Diffusion</li> <li>(113) Score Matching</li> <li>(114) Likelihood Estimation</li> <li>(115) Energy-Based Models</li> <li>(116) Flow-Based Models</li> </ul>"},{"location":"prompts/05-concept-taxonomy/#7-advanced-specialized-topics","title":"7. Advanced &amp; Specialized Topics","text":"<p>Cutting-edge methods, hardware accelerators, reinforcement learning, and larger-scale automation.</p> <ul> <li>(71) Sequence Modeling (repeated if focusing on advanced sequences)</li> <li>(77) Language Modeling</li> <li>(78) Text Generation</li> <li>(117) Prompt Engineering</li> <li>(119) Large Language Models (LLMs)</li> <li>(120) ChatGPT Concept</li> <li>(131) RL Definition</li> <li>(132) Markov Decision Process (MDP)</li> <li>(133) Value Functions</li> <li>(134) Policy Gradient</li> <li>(135) Q-Learning</li> <li>(136) Deep Q-Network (DQN)</li> <li>(137) Actor-Critic</li> <li>(138) Reward Shaping</li> <li>(140) Baseline Algorithms</li> <li>(151) GPU Acceleration</li> <li>(152) TPU Acceleration</li> <li>(153) Memory Management</li> <li>(154) Model Compression</li> <li>(155) Quantization</li> <li>(156) Pruning</li> <li>(157) Edge Deployment</li> <li>(158) Cloud Services</li> <li>(159) AutoML</li> <li>(167) Data Parallelism</li> <li>(168) Model Parallelism</li> <li>(169) Checkpointing</li> </ul>"},{"location":"prompts/05-concept-taxonomy/#8-real-world-applications","title":"8. Real-World Applications","text":"<p>Domains and example uses that illustrate how AI/ML solutions are deployed.</p> <ul> <li>(70) Object Detection (also in CNNs)</li> <li>(181) Computer Vision</li> <li>(182) Natural Language Processing (NLP)</li> <li>(183) Speech Recognition</li> <li>(184) Medical Imaging</li> <li>(185) Drug Discovery</li> <li>(186) Protein Folding</li> <li>(187) Autonomous Driving</li> <li>(188) Robotics</li> <li>(189) Financial Forecasting</li> <li> <p>(190) Recommender Systems</p> </li> <li> <p>Interpretation, Ethics, &amp; Fairness</p> </li> </ul> <p>Ensuring AI systems are transparent, fair, secure, and used responsibly.</p> <ul> <li>(40) Data Ethics</li> <li>(141) Model Interpretability</li> <li>(142) Explainable AI (XAI)</li> <li>(143) SHAP</li> <li>(144) LIME</li> <li>(145) Fairness</li> <li>(146) Bias Mitigation</li> <li>(147) Privacy</li> <li>(148) Security</li> <li>(149) Adversarial Examples</li> <li>(150) Responsible AI</li> </ul>"},{"location":"prompts/05-concept-taxonomy/#10-mlops-project-workflow","title":"10. MLOps &amp; Project Workflow","text":"<p>Practical, organizational, and life-cycle aspects of putting ML/DL models into production and managing teams.</p> <ul> <li>(160) MLOps</li> <li>(170) Version Control</li> <li>(191) Project Scoping</li> <li>(192) Requirement Analysis</li> <li>(193) Data Acquisition (also in Data Prep)</li> <li>(194) Data Annotation (also in Data Prep)</li> <li>(195) Resource Allocation</li> <li>(196) Team Collaboration</li> <li>(197) Version Control Workflow</li> <li>(198) Agile Methods</li> <li>(199) Code Review</li> <li>(200) Documentation</li> </ul>"},{"location":"prompts/05-concept-taxonomy/#11-goals","title":"11. Goals","text":"<p>Metrics and broader objectives that guide model selection, validation, and success criteria.</p> <ul> <li>(28) Evaluation Metrics</li> <li>(171) Accuracy</li> <li>(172) Precision</li> <li>(173) Recall</li> <li>(174) F1 Score</li> <li>(175) AUC-ROC</li> <li>(176) Confusion Matrix</li> <li>(177) Top-1 Vs Top-5 Accuracy</li> <li>(178) BLEU Score</li> <li>(179) Perplexity</li> <li>(180) Mean Squared Error (MSE)</li> </ul>"},{"location":"prompts/05-concept-taxonomy/#notes-on-overlaps","title":"Notes on Overlaps","text":"<ul> <li>Some items (e.g., \"Overfitting Vs Underfitting\") appear in both Terms and Definitions and Training &amp; Optimization, because they are foundational distinctions and deeply tied to optimization.</li> <li>\"Object Detection,\" \"Data Ethics,\" \"Data Acquisition,\" and several others also appear in more than one category when relevant.</li> </ul> <p>This multi-category approach reflects the reality that many deep learning concepts straddle theoretical and practical lines and can belong in more than one \"bucket.\" Depending on your course or textbook structure, you may wish to split them differently or provide cross-references.</p>"},{"location":"prompts/05-concept-taxonomy/#final-csv-file","title":"Final CSV File","text":"<p>Prompt</p> <p>That was excellent.  Now please regenerate the CSV file, but this time please add a new column for TaxonomyID.  Use the numbers for each category as the TaxonomyID.</p> <p>The format of the new file is:</p> <ol> <li>Column 1: ConceptID</li> <li>Column 2: ConceptLabel</li> <li>Column 3: Dependencies</li> <li>Column 4: TaxonomyID</li> </ol>"},{"location":"prompts/06-glossary-of-terms/","title":"Generating a Glossary","text":"<p>Prompt</p> <p>Next we need a glossary of terms.  For each of the 200 concepts, please create a ISO 11179 definition that is precise, concise, distinct and non-circular.  When appropriate, give an example of how this term is used in the course.  Return each concept label in Markdown level 4 and the definition for the term in the body text.  Use Example: before the example.</p> <p>Return the entire glossary of terms in a single markdown file.  Place \"# Glossary of Terms\" at the top of the file.  Return the terms in alphabetical order.</p>"},{"location":"prompts/06-glossary-of-terms/#result","title":"Result","text":""},{"location":"prompts/07-equations/","title":"Generating Deep Learning Equations","text":"<p>Prompt</p> <p>Create a list of the 100 most commonly used equations in a college level course in deep learning.</p> <p>For each equation, return the following:</p> <ol> <li>The name of the equation in markdown level 4.</li> <li>Within the body, return the equation in LaTeX format</li> <li>Surround the equation with dollar signs</li> <li>For each variable in the equation, add a \"where:\" that defines each variable</li> <li>Put blank lines around the list of variables</li> <li>Wrap the variables names in dollar signs</li> </ol> <p>Examples:</p>"},{"location":"prompts/07-equations/#slope-and-intercept","title":"Slope and Intercept","text":"<p>$y = m * x + b$</p> <p>where:</p> <ul> <li>$y$ is the vertical axis</li> <li>$x$ is the horizontal axis</li> <li>$m$ is the slope</li> <li>$b$ is the intercept</li> </ul>"},{"location":"prompts/07-equations/#area-of-a-circle","title":"Area of a Circle","text":"<p>$A = 2\\pi r^2$ where:</p> <ul> <li>$A$ is the area of the circle</li> <li>$r$ is the radius</li> </ul>"},{"location":"sims/","title":"List of Deep Learning MicroSims","text":""},{"location":"sims/#learning-graph","title":"Learning Graph","text":"<p>Learning Graph</p>"},{"location":"sims/learning-graph/","title":"Learning Graph for Deep Learning Course","text":"<p>Run Learning Graph MicroSim</p>"}]}